{
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5,
  "cells": [
    {
      "id": "metadata",
      "cell_type": "markdown",
      "source": "<div style=\"border: 2px solid #8A9AD0; margin: 1em 0.2em; padding: 0.5em;\">\n\n# Foundational Aspects of Machine Learning using Python\n\nby [Wandrille Duchemin](https://training.galaxyproject.org/hall-of-fame/wandrilled/)\n\nCC-BY licensed content from the [Galaxy Training Network](https://training.galaxyproject.org/)\n\n**Objectives**\n\n- to do\n\n**Objectives**\n\n- general sklearn syntax intro\n- overfit/underfit\n- the need for regularization\n- cross validation and a test set\n- metrics and imbalance\n\n**Time Estimation: 3H**\n</div>\n",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-0",
      "source": "\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-1",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-2",
      "source": "\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-3",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.pylab as pylab\n",
        "import pandas as pd\n",
        "from operator import itemgetter\n",
        "\n",
        "from warnings import filterwarnings\n",
        "\n",
        "pylab.rcParams['figure.figsize'] = 5, 5\n",
        "plt.rc(\"font\", size=10)\n",
        "\n",
        "\n",
        "plt.rc('xtick', color='k', labelsize='medium', direction='in')\n",
        "plt.rc('xtick.major', size=8, pad=12)\n",
        "plt.rc('xtick.minor', size=8, pad=12)\n",
        "\n",
        "plt.rc('ytick', color='k', labelsize='medium', direction='in')\n",
        "plt.rc('ytick.major', size=8, pad=12)\n",
        "plt.rc('ytick.minor', size=8, pad=12)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-4",
      "source": "<p>So far we have fitted our curves and doing so we have found the  best model explaining the point that we had for the fitting.</p>\n<p>We also saw that we could choose different models according to how much the improvement obtained was worth the complexification of the model. But again we did it on the whole data that we had. We never really check how well our data was generalizing to points never seen before, or by how much the model we found was subject to outliers.</p>\n<p>Machine learning procedures allow us to take those considerations into account. After highlighting the few caveats of the procedures we have used in the former notebook, we will introduce the foundation of the machine learning way to model.</p>\n<p>More particularly we will see that the machine learning paradigm modifies the function to optimize that we have seen before by adding a penalty to covariables that generalize badly. We will also see that in a machine learning procedure, the generalization is approached by fitting and evaluating mutliple times your model on subset of your data.</p>\n<p>The machine learning paradigm emphasizes the importance of building a general model that will be good at dealing with future, unknown, data points rather than being the best model on the data that we have now.</p>\n<blockquote class=\"agenda\" style=\"border: 2px solid #86D486;display: none; margin: 1em 0.2em\">\n<div class=\"box-title agenda-title\" id=\"agenda\">Agenda</div>\n<p>In this tutorial, we will cover:</p>\n<ol id=\"markdown-toc\">\n<li><a href=\"#exploring-model-generalization-in-previous-methods\" id=\"markdown-toc-exploring-model-generalization-in-previous-methods\">Exploring model generalization in previous methods.</a>    <ol>\n<li><a href=\"#model-sensibility-to-a-few-particular-points\" id=\"markdown-toc-model-sensibility-to-a-few-particular-points\">Model sensibility to a few particular points.</a></li>\n</ol>\n</li>\n</ol>\n</blockquote>\n<h1 id=\"exploring-model-generalization-in-previous-methods\">Exploring model generalization in previous methods.</h1>\n<h2 id=\"model-sensibility-to-a-few-particular-points\">Model sensibility to a few particular points.</h2>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-5",
      "source": [
        "df_h_n=pd.read_csv(\"data/Human_nuisance.csv\", index_col=0)\n",
        "df_h_n.rename(columns={ \"Breeding density(individuals per ha)\":\"Breeding\",\n",
        "                       \"Number of pedestrians per ha per min\":\"N\"},inplace=True)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8,6))\n",
        "ax.plot(df_h_n.N,df_h_n.Breeding,'ro')\n",
        "ax.set_ylabel(\"Breeding density_h_n(individuals per ha)\")\n",
        "ax.set_xlabel(\"Number of pedestrians per ha per min\")\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-6",
      "source": "<!--<a href=\"./images/output_6_0.png\" rel=\"noopener noreferrer\"><img src=\"./images/output_6_0.png\"  alt=\"png. \"  width=\"702\" height=532 loading=\"lazy\"></a>-->\n<p>Let’s get rid of the two last points. We could argue that they look fishy since they are the only two points that go up. Maybe they are driving the cubic fit?</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-7",
      "source": [
        "fig, ax = plt.subplots(figsize=(8,6))\n",
        "ax.plot(df_h_n.N[:-2],df_h_n.Breeding[:-2],'ro')\n",
        "ax.set_ylabel(\"Breeding density(individuals per ha)\")\n",
        "ax.set_xlabel(\"Number of pedestrians per ha per min\")\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-8",
      "source": "\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-9",
      "source": [
        "import statsmodels\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "list_co=[]#list of covariable\n",
        "\n",
        "\n",
        "df_nuisance=df_h_n.copy()\n",
        "\n",
        "models = []\n",
        "logLikelihoods = []\n",
        "\n",
        "for i in range(1,5):\n",
        "\n",
        "    df_nuisance[\"N\"+str(i)]=df_nuisance.N**i\n",
        "\n",
        "    list_co.append( \"N\"+str(i) )\n",
        "\n",
        "    ## create the model, without the last 2 points\n",
        "    model = smf.ols(\"Breeding ~ \" + \"+\".join(list_co) , data = df_nuisance.iloc[:-2, :] )\n",
        "    results = model.fit()#we do the actual fit\n",
        "\n",
        "    models.append(\"+\".join(list_co))\n",
        "    logLikelihoods.append( results.llf )\n",
        "\n",
        "logLikelihoods"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-10",
      "source": "<p>[np.float64(-125.86306783486532),\n     np.float64(-112.64380299806213),\n     np.float64(-110.71030133123855),\n     np.float64(-103.39762229283633)]</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-11",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "for i in range(1,len(logLikelihoods)):\n",
        "    #calculating the pvalue for the LRT between the models\n",
        "    pval=1-stats.chi2.cdf(2*(logLikelihoods[i]-logLikelihoods[i-1]),1)\n",
        "\n",
        "    print(\"model {:<10} - model {:<12} : LRT p-value = {:.2e}\".format(models[i-1],\n",
        "                                                                     models[i],\n",
        "                                                                     pval))\n",
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-12",
      "source": "<p>model N1         - model N1+N2        : LRT p-value = 2.72e-07\n    model N1+N2      - model N1+N2+N3     : LRT p-value = 4.92e-02\n    model N1+N2+N3   - model N1+N2+N3+N4  : LRT p-value = 1.31e-04</p>\n<p>You see that the choice between quadratic and cubic is associated to a fairly high p-value here (~0.0492).</p>\n<p>Let’s check how the model behaves:</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-13",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "fig, ax = plt.subplots(1, 2,figsize=(14,7))\n",
        "## Quadratic model\n",
        "\n",
        "for i, variables in enumerate( [\"N1+N2\",\"N1+N2+N3\"] ):\n",
        "\n",
        "    model = smf.ols(\"Breeding ~ \"+variables , data = df_nuisance.iloc[:-2] )\n",
        "    results = model.fit()#we do the actual fit\n",
        "\n",
        "    predicted = results.predict( df_nuisance )\n",
        "\n",
        "    ## computing goodness of fit metrics\n",
        "    R2_2_h_n = r2_score(df_nuisance.Breeding[:-2], predicted[:-2])\n",
        "    MSE_2_h_n = mean_squared_error(df_nuisance.Breeding[:-2],predicted[:-2])\n",
        "\n",
        "    R2_22_h_n = r2_score(df_nuisance.Breeding[-2:], predicted[-2:])\n",
        "    MSE_22_h_n = mean_squared_error(df_nuisance.Breeding[-2:], predicted[-2:])\n",
        "\n",
        "\n",
        "    ax[i].scatter( x = df_nuisance.N , y = df_nuisance.Breeding , c = ['teal']*(df_h_n.shape[0]-2) + ['orange']*2 )\n",
        "    ax[i].plot(df_nuisance.N[:-2],predicted[:-2] ,'r-')\n",
        "    ax[i].plot(df_nuisance.N[-3:],predicted[-3:] ,'r--')\n",
        "\n",
        "    ax[i].set_title(variables+'\\nall but 2 : R2={0:.2f}, MSE={1:.2f}\\n last 2 : R2={2:.2f}, MSE={3:.2f}'.format(R2_2_h_n,MSE_2_h_n,R2_22_h_n,MSE_22_h_n),fontsize=13)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-14",
      "source": "<!--<a href=\"output_12_0.png\" rel=\"noopener noreferrer\"><img src=\"output_12_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>The cubic function is still overall better even on the points not used for the fitting (we actually kind of expected that).</p>\n<h2 id=\"how-does-the-model-change-according-to-random-data-subsamples\">How does the model change according to random data subsamples.</h2>\n<p>We should check if this kind of behaviour where it becomes difficult to assert a good model is general or is it just because we decided to get rid of those two particular points. Let’s check with more random subsamples and something a bit more balanced between number of points for fitting and for checking : here two is bit low.</p>\n<p>Just for memory’s sake, let’s fit all the data as we did before</p>\n<p><em>Note : to run the code below you need to install pydotplus (!pip install pydotplus) if you don’t have it already</em></p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-15",
      "source": [
        "from utils import poly_fit_train_test\n",
        "\n",
        "cubic=[]\n",
        "quadratic=[]\n",
        "\n",
        "## we reshape N to ake it compatible with the sklearn functions we use there\n",
        "Nreshaped = np.array( df_nuisance.N ).reshape(-1,1)\n",
        "\n",
        "for i in range(3):# here we are fitting our model and checking it on different random subsample of the data\n",
        "    seed = np.random.randint( 10**4 )\n",
        "    fig, ax = plt.subplots( 1 , 2 , figsize=(10,5) )\n",
        "\n",
        "    cubic_metrics = poly_fit_train_test( Nreshaped,\n",
        "                                        df_nuisance.Breeding, seed = seed, deg = 3 , ax = ax[0])#this contain the fit and some scoring metric\n",
        "    quad_metrics  = poly_fit_train_test( Nreshaped,\n",
        "                                        df_nuisance.Breeding, seed = seed, deg = 2 , ax = ax[1])\n",
        "\n",
        "    cubic.append(cubic_metrics)\n",
        "    quadratic.append(quad_metrics)\n",
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-16",
      "source": "<!--<a href=\"output_15_0.png\" rel=\"noopener noreferrer\"><img src=\"output_15_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!--<a href=\"output_15_1.png\" rel=\"noopener noreferrer\"><img src=\"output_15_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!--<a href=\"output_15_2.png\" rel=\"noopener noreferrer\"><img src=\"output_15_2.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>Let’s see what the R2 are between cubic and quadratic for many splitting of the dataset and for known and unknown data points.</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-17",
      "source": [
        "cubic=[]\n",
        "quadratic=[]\n",
        "for i in range(500):# same as before but on way more different split\n",
        "    temp3=poly_fit_train_test(Nreshaped,df_nuisance.Breeding,deg=3,ax=None)\n",
        "    temp2=poly_fit_train_test(Nreshaped,df_nuisance.Breeding,deg=2,ax=None)\n",
        "\n",
        "    if min(temp3)>0 and min(temp2)>0:\n",
        "        cubic.append(temp3)\n",
        "        quadratic.append(temp2)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-18",
      "source": "\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-19",
      "source": [
        "cubic_known , cubic_new =  list( zip( *cubic ) )\n",
        "quadratic_known , quadratic_new =  list( zip( *quadratic ) )"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-20",
      "source": "\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-21",
      "source": [
        "fig, ax = plt.subplots(1, 2,figsize=(14,7))\n",
        "ax[0].hist([cubic_known,quadratic_known],label=['cubic','quadratic'])\n",
        "ax[0].set_title('Known')\n",
        "ax[0].legend(loc='best')\n",
        "ax[0].set_xlabel('R2')\n",
        "\n",
        "ax[1].hist([cubic_new,quadratic_new],label=['cubic','quadratic'])\n",
        "ax[1].set_title('New')\n",
        "ax[1].legend(loc='best')\n",
        "ax[1].set_xlabel('R2')\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-22",
      "source": "<!--<a href=\"output_20_0.png\" rel=\"noopener noreferrer\"><img src=\"output_20_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>We see here that in most of those random cases the cubic model gives better prediction on the new data points. Yet all the outcome of those fitting are a bit different. How do we reconcile them?</p>\n<h2 id=\"splitting-data-and-regularization\">Splitting data and regularization.</h2>\n<p><strong>Maybe then, what you would like to do is to find the model that is best at predicting new data point whatever the specific data you fit on is.</strong> You don’t want to underfit neither overfit and start modeling the noise of your data. You need to find a compromize. You will sometime hear people use the terms bias variance problem or the <strong>curse of dimensionality</strong> when refering to that problem.</p>\n<p>The approach used for that is a mix of what’s called regularization, and splitting of your dataset. <strong>Regularization</strong>, as its name indicates has the ambition to smoothen your fit, to make sure that you don’t start to fit the noise in your data so you can be as general in your prediction as possible.  It does that by putting another layer of constraints on your covariables (features). That constraint on your covariable translates in either the objective function you want to maximize/minimize (by adding a term in your least square or your maximum likelihood), or by constraining the space of available models.</p>\n<p>Whatever that regularization is, its strength is always optimized by looking at subsamples of the dataset.</p>\n<p>It is a nice automated method for model exploration, generalization and testing, which for me really defines machine learning. All of this is related to something called the curse of dimensionality. <strong>And in any case, it relies on a splitting of your data set between at least a train and a test set</strong>.</p>\n<!--<a href=\"image/Presentation1.png\" rel=\"noopener noreferrer\"><img src=\"image/Presentation1.png\"  alt=\"presentation1. \"   loading=\"lazy\"></a>-->\n<p>You need the test set to assess the actual generalization of your model. <strong>This test set should not be touched until the evaluation of your model.</strong> Ideally by then you are looking at a model which is both good on the train and the test set.</p>\n<p>You can imagine that it is the noise that makes the coefficient in front of the 149th polynomial look very important (so big), because here by construction we know that a fit with a polynomial greater than 3 is going to fit the noise. So you should penalize big coefficients unless they are absolutely necessary. Here necessary is to be understood as necessary for understanding all the subsamples of your data.</p>\n<h1 id=\"regularization-in-the-case-of-ols-and-glm\">Regularization in the case of OLS and GLM</h1>\n<p>In case of a Least Square fitting, you just have to add to your sum of squared errors a function that takes into account the parameters in front of your covariables. Looking at those equations you penalize weights that will take too much importance in the fitting, unless they are important in every substet of data that you fit on. We will see how those subsets are designed later on. By evaluating this new loss function on many subsets of the data we can perfom model comparison and choose model generalization, all at once.</p>\n<blockquote class=\"comment\" style=\"border: 2px solid #ffecc1; margin: 1em 0.2em\">\n<div class=\"box-title comment-title\" id=\"comment\"><i class=\"far fa-comment-dots\" aria-hidden=\"true\" ></i> Comment</div>\n<p>we report here the formulas used in <code style=\"color: inherit\">scikit-learn</code> functions. Other libraries may have a different parameterization, but the concepts stay the same</p>\n</blockquote>\n<table>\n<tbody>\n<tr>\n<td>&#36;\\frac{1}{2n}\\sum_i (y_i-f(\\pmb X_i,\\pmb{\\beta}))^2 + \\alpha\\sum_{j}</td>\n<td>\\beta_{j}</td>\n<td>&#36; , <strong>l1 regularization</strong> (Lasso) &#36;\\alpha&#36; being the weight that you put on that regularization</td>\n</tr>\n</tbody>\n</table>\n<p>&#36;\\sum_i (y_i-f(\\pmb X_i,\\pmb{\\beta}))^2 + \\alpha\\sum_{j}\\beta_{j}^{2}&#36; , <strong>l2 regularization</strong> (Ridge)</p>\n<table>\n<tbody>\n<tr>\n<td>&#36;\\frac{1}{2n}\\sum_i (y_i-f(\\pmb X_i,\\pmb{\\beta}))^2 + \\alpha\\sum_{j}(\\rho</td>\n<td>\\beta_{j}</td>\n<td>+\\frac{(1-\\rho)}{2}\\beta_{j}^{2})&#36; , <strong>elasticnet</strong></td>\n</tr>\n</tbody>\n</table>\n<p>For a deeper understanding of those notions, you may look at :</p>\n<ul>\n<li>\n<p>https://www.datacamp.com/community/tutorials/tutorial-ridge-lasso-elastic-net</p>\n</li>\n<li>\n<p>https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a</p>\n</li>\n</ul>\n<p>In case of a logistic regression you want to maximize your log likelihood which is now penalized by one of those functions:</p>\n<table>\n<tbody>\n<tr>\n<td>&#36;\\sum_{i}log(p_{i}) - \\alpha\\sum_{j}</td>\n<td>\\beta_{j}</td>\n<td>&#36; , <strong>l1 regularization</strong> (Lasso)</td>\n</tr>\n</tbody>\n</table>\n<p>&#36;\\sum_{i}log(p_{i}) - \\frac{\\alpha}{2}\\sum_{j}\\beta_{j}^{2}&#36; , <strong>l2 regularization</strong> (Ridge)</p>\n<table>\n<tbody>\n<tr>\n<td>&#36;\\sum_{i}log(p_{i}) - \\alpha\\sum_{j}(\\rho</td>\n<td>\\beta_{j}</td>\n<td>+\\frac{(1-\\rho)}{2}\\beta_{j}^{2})&#36; , <strong>elasticnet</strong></td>\n</tr>\n</tbody>\n</table>\n<p>Rule is : <strong>when you hypothesize that you have sparse features and so you believe that among all those features only a small subset is going to be interesting (but of course you don’t know which ones…) then you try to use the regularization that will tend to put more of your features at the zero weight (the l1 regularization) and so reduce the complexity of your model.</strong> This l1 norm that collapses non-important features to zero is another way to do feature selection.</p>\n<p>Now, we need a way to find this coefficient &#36;\\alpha&#36; which will set the strength of our regularization. This parameter is called an <strong>hyperparameter</strong>, and cannot be found directly like the others, since even if it is part of a new model it serve a generalization purpose and so should not be found by optimization on our full dataset. To do that on top of our first splitting between train dataset and test dataset, we will need to perfom some more splitting of our train data set.</p>\n<blockquote class=\"comment\" style=\"border: 2px solid #ffecc1; margin: 1em 0.2em\">\n<div class=\"box-title comment-title\" id=\"comment-1\"><i class=\"far fa-comment-dots\" aria-hidden=\"true\" ></i> Comment</div>\n<p>the polynomial number we were using before is also an hyperparameter and can be find by the same technic consisting of splitting our data. Later on we will see other hyperparameters that are either related to model choice or regularization or intrically both.</p>\n</blockquote>\n<p>Let’s apply this on a couple of new datasets</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-23",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "diabetes = load_diabetes()\n",
        "\n",
        "df_diabetes=pd.DataFrame(diabetes['data'],\n",
        "                         columns=  diabetes['feature_names'])\n",
        "\n",
        "df_diabetes.head()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-24",
      "source": "<div>\n<style scoped=\"\">\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n<thead>\n<tr style=\"text-align: right;\">\n<th></th>\n<th>age</th>\n<th>sex</th>\n<th>bmi</th>\n<th>bp</th>\n<th>s1</th>\n<th>s2</th>\n<th>s3</th>\n<th>s4</th>\n<th>s5</th>\n<th>s6</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<th>0</th>\n<td>0.038076</td>\n<td>0.050680</td>\n<td>0.061696</td>\n<td>0.021872</td>\n<td>-0.044223</td>\n<td>-0.034821</td>\n<td>-0.043401</td>\n<td>-0.002592</td>\n<td>0.019907</td>\n<td>-0.017646</td>\n</tr>\n<tr>\n<th>1</th>\n<td>-0.001882</td>\n<td>-0.044642</td>\n<td>-0.051474</td>\n<td>-0.026328</td>\n<td>-0.008449</td>\n<td>-0.019163</td>\n<td>0.074412</td>\n<td>-0.039493</td>\n<td>-0.068332</td>\n<td>-0.092204</td>\n</tr>\n<tr>\n<th>2</th>\n<td>0.085299</td>\n<td>0.050680</td>\n<td>0.044451</td>\n<td>-0.005670</td>\n<td>-0.045599</td>\n<td>-0.034194</td>\n<td>-0.032356</td>\n<td>-0.002592</td>\n<td>0.002861</td>\n<td>-0.025930</td>\n</tr>\n<tr>\n<th>3</th>\n<td>-0.089063</td>\n<td>-0.044642</td>\n<td>-0.011595</td>\n<td>-0.036656</td>\n<td>0.012191</td>\n<td>0.024991</td>\n<td>-0.036038</td>\n<td>0.034309</td>\n<td>0.022688</td>\n<td>-0.009362</td>\n</tr>\n<tr>\n<th>4</th>\n<td>0.005383</td>\n<td>-0.044642</td>\n<td>-0.036385</td>\n<td>0.021872</td>\n<td>0.003935</td>\n<td>0.015596</td>\n<td>0.008142</td>\n<td>-0.002592</td>\n<td>-0.031988</td>\n<td>-0.046641</td>\n</tr>\n</tbody>\n</table>\n</div>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-25",
      "source": [
        "%%time\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# the SGDRegressor from sklearn\n",
        "# uses gradient descent to find the best fit with the\n",
        "# objective function modified with the regularization term\n",
        "\n",
        "logalphas = []\n",
        "\n",
        "coef_dict = {'name' : [],\n",
        "             'val' : [],\n",
        "             'log-alpha' : []}\n",
        "r2 = []\n",
        "\n",
        "for alpha in np.logspace(-1,1,50):\n",
        "\n",
        "    reg_diabetes = SGDRegressor( penalty='l1' , alpha = alpha , max_iter=10000 )\n",
        "    reg_diabetes.fit( df_diabetes , diabetes['target'] )\n",
        "\n",
        "    logalphas.append(np.log10(alpha))\n",
        "    r2.append( r2_score( diabetes['target'] , reg_diabetes.predict(df_diabetes) ) )\n",
        "\n",
        "    coef_dict['name'] += list( df_diabetes.columns )\n",
        "    coef_dict['val'] += list( reg_diabetes.coef_ )\n",
        "    coef_dict['log-alpha'] += [np.log10(alpha)]* len(df_diabetes.columns )\n",
        "\n",
        "coef_df = pd.DataFrame(coef_dict)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-26",
      "source": "\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-27",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "fig,ax = plt.subplots(1,2,figsize = (14,7))\n",
        "\n",
        "ax[0].plot(logalphas , r2)\n",
        "ax[0].set_xlabel(\"log10( alpha )\")\n",
        "ax[0].set_ylabel(\"R2\")\n",
        "\n",
        "sns.lineplot( x = 'log-alpha' , y='val' , hue = 'name' , data= coef_df , ax = ax[1])\n",
        "\n",
        "fig.suptitle(\"regression of diabetes data with an L1 regularization.\")\n",
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-28",
      "source": "<!--<a href=\"output_28_1.png\" rel=\"noopener noreferrer\"><img src=\"output_28_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<blockquote class=\"question\" style=\"border: 2px solid #8A9AD0; margin: 1em 0.2em\">\n<div class=\"box-title question-title\" id=\"question\"><i class=\"far fa-question-circle\" aria-hidden=\"true\" ></i> Question</div>\n<p>adapt the code above to generate this plot with an <strong>l2</strong> penalty. How do you interpret the difference?\nThis is great, but how do we choose which level of regularization we want ?</p>\n<br/><details style=\"border: 2px solid #B8C3EA; margin: 1em 0.2em;padding: 0.5em; cursor: pointer;\"><summary>👁 View solution</summary>\n<div class=\"box-title solution-title\" id=\"solution\"><button class=\"gtn-boxify-button solution\" type=\"button\" aria-controls=\"solution\" aria-expanded=\"true\"><i class=\"far fa-eye\" aria-hidden=\"true\" ></i> <span>Solution</span><span class=\"fold-unfold fa fa-minus-square\"></span></button></div>\n<p>Answer</p>\n</details>\n</blockquote>\n<p>It is a general rule that <strong>as you decrease &#36;\\alpha&#36;, the &#36;R^2&#36; on the data used for the fit increase</strong>, i.e. you risk overfitting.</p>\n<p>Consequently, we cannot choose the value of &#36;\\alpha&#36; parameter from the data used to fit alone; we call such a parameter an <strong>hyper-parameter</strong>.</p>\n<p><strong>Question:</strong> what are other hyper-parameters we could optimize at this point?</p>\n<p>In order to find the optimal value of an hyper-parameter, we can separate our data into:</p>\n<ul>\n<li>a <strong>train set</strong> : used to fit the model</li>\n<li>a <strong>validation set</strong> : used to evaluate how our model perform on new data</li>\n</ul>\n<p>Here the &#36;R^2&#36; stays fairly low even with little to no regularization, so overfitting is not that likely (I have checked, it is not).</p>\n<p>Let’s look at another data-set where overfitting is an issue.</p>\n<p><a href=\"https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-016-1043-4\">Acharjee et al.2016</a> propose several -omic dataset which they used to predict and gain knowledge on various phenotypic traits in potatos.</p>\n<p>Here, we will concentrate on the their transcriptomics dataset and the phenotypic trait of the potato coloration.</p>\n<p>We have pre-selected and normalized the 200 most promising genes (out of ~15 000).</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-29",
      "source": [
        "df = pd.read_csv(\"data/potato_data.phenotypic.csv\" , index_col=0)\n",
        "y = df[\"Flesh Colour\"]\n",
        "y.describe()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-30",
      "source": "<p>count    86.000000\n    mean     24.054824\n    std      13.023169\n    min       6.887500\n    25%      12.664600\n    50%      24.278800\n    75%      31.305050\n    max      57.035100\n    Name: Flesh Colour, dtype: float64</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-31",
      "source": [
        "dfTT = pd.read_csv(\"data/potato_data.transcriptomic.top200norm.csv\" , index_col = 0)\n",
        "dfTT.head()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-32",
      "source": "\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-33",
      "source": [
        "%%time\n",
        "X = np.array( dfTT )\n",
        "\n",
        "I = list( range(X.shape[0]))\n",
        "np.random.shuffle( I )\n",
        "\n",
        "# we will use the first 30 points to evaluate the model\n",
        "X_valid = X[ I[:30] , :]\n",
        "y_valid = y.iloc[I[:30]]\n",
        "\n",
        "# we will use the rest to train the model\n",
        "X_train = X[ I[30:] , :]\n",
        "y_train = y.iloc[I[30:]]\n",
        "\n",
        "\n",
        "logalphas = []\n",
        "\n",
        "r2_train = []\n",
        "r2_valid = []\n",
        "\n",
        "for alpha in np.logspace(-3,2,200):\n",
        "\n",
        "    reg_diabetes = SGDRegressor( penalty='l1' , alpha = alpha , max_iter=2000 )\n",
        "    reg_diabetes.fit( X_train , y_train )\n",
        "\n",
        "    logalphas.append(np.log10(alpha))\n",
        "    r2_train.append( r2_score( y_train , reg_diabetes.predict(X_train) ) )\n",
        "    r2_valid.append( r2_score( y_valid , reg_diabetes.predict(X_valid) ) )\n",
        "\n",
        "## plotting and reporting\n",
        "bestI = np.argmax(r2_valid)\n",
        "bestLogAlpha = logalphas[bestI]\n",
        "bestR2_valid = r2_valid[bestI]\n",
        "\n",
        "fig,ax = plt.subplots(figsize = (10,5))\n",
        "fig.suptitle(\"best alpha : {:.2f} - validation R2 : {:.2f}\".format(10**bestLogAlpha , bestR2_valid))\n",
        "ax.plot( logalphas, r2_train , label='train set' )\n",
        "ax.plot( logalphas, r2_valid , label='validation set' )\n",
        "ax.scatter( [bestLogAlpha] , [bestR2_valid]  , c='red')\n",
        "ax.set_xlabel(\"log10( alpha )\")\n",
        "ax.set_ylabel(\"R2\")\n",
        "ax.set_ylim(-0.1,1.1)\n",
        "ax.legend()\n",
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-34",
      "source": "<!--<a href=\"output_35_2.png\" rel=\"noopener noreferrer\"><img src=\"output_35_2.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>So now, with the help of a validation set, we can clearly see the phases :</p>\n<ul>\n<li><strong>underfitting</strong> : for high &#36;\\alpha&#36;, the performance is low for both the train and the validation set</li>\n<li><strong>overfitting</strong> : for low &#36;\\alpha&#36;, the performance is high for the train set, and low for the validation set</li>\n</ul>\n<p>We want the equilibrium point between the two where performance is ideal for the validation set.</p>\n<p><strong>Problem :</strong> if you run the code above several time, you will see that the optimal point varies due to the random assignation to train or validation set.</p>\n<p>There exists a myriad of possible strategies to deal with that problem, such as repeating the above many times and taking the average of the results for instance.\nNote also that this problem gets less important as the validation set size increases.</p>\n<p>So now, on top of our earlier regression model, we have added :</p>\n<ul>\n<li>an <strong>hyper-parameter</strong> : &#36;\\alpha&#36;, the strength of the regularization term</li>\n<li>a <strong>validation strategy</strong> for our model in order to avoid overfitting</li>\n</ul>\n<p>That’s it, we are now in the world of Machine Learning.</p>\n<h1 id=\"the-machine-learning-framework\">The machine learning framework</h1>\n<p>Machine Learning, in a sense, is procuppied with the problem of <strong>overfitting</strong>, or how much model perform on new data.</p>\n<p>To that end, we begin by dividing our data into :</p>\n<ul>\n<li><strong>train</strong> set : find the best model</li>\n<li><strong>test</strong> set  : give an honest evaluation of how the model perform on completely new data.</li>\n</ul>\n<p>The train set will be used to find the best model, with the <strong>best parameter and hyper-parameter values</strong>.</p>\n<p>The test set will only be used at the very end, to report model performance.</p>\n<p>However, as we have seen the hyper-parameter cannot be set directly from the data that was used to train the model, thus, we deploy a <strong>cross-validation strategy</strong> by further splitting the train set.</p>\n<p>For example, consider one of the most common strategy : <strong>k-fold cross validation</strong></p>\n<!--<a href=\"image/kfold.png\" rel=\"noopener noreferrer\"><img src=\"image/kfold.png\"  alt=\"k-fold validation. \"   loading=\"lazy\"></a>-->\n<p>In k-fold cross-validation, you split you data in &#36;k&#36; subpart, called fold.</p>\n<p>Then, for a given hyper-parameter values combination, you actually train &#36;k&#36; model: each time you use a different fold for validation (and the remaining &#36;k-1&#36; folds for training).</p>\n<p>You then compute the average performance across all fold : this is the <strong>cross-validated performance</strong>.</p>\n<p>If we code ourselves a naive version of this, it could look something like this:</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-35",
      "source": [
        "## I make a helper function with tests a bunch for a given validation set of alpha values\n",
        "def testAlphas( X_train , y_train , X_valid , y_valid , alphas):\n",
        "    r2_valid = []\n",
        "\n",
        "    for alpha in alphas:\n",
        "        reg_diabetes = SGDRegressor( penalty='l1' , alpha = alpha , max_iter=2000 )\n",
        "        reg_diabetes.fit( X_train , y_train )\n",
        "        r2_valid.append( r2_score( y_valid , reg_diabetes.predict(X_valid) ) )\n",
        "\n",
        "    return r2_valid\n",
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-36",
      "source": "\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-37",
      "source": [
        "\n",
        "k = 4 ## 4-fold\n",
        "\n",
        "## ugly initialization , we have to handle the fact that the number of sample is not perfectly divisible by 4\n",
        "I = np.array( ( [0,1,2,3] * ((X.shape[0]//k)+1) )[:X.shape[0]] )\n",
        "\n",
        "## shuffle randomly\n",
        "np.random.shuffle( I )\n",
        "print( I )"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-38",
      "source": "<p>[2 3 0 3 0 0 0 2 2 0 3 1 0 1 2 1 0 3 1 2 2 1 2 3 3 2 1 3 1 0 1 2 1 1 1 3 3\n     3 1 1 3 0 1 2 2 1 3 0 3 2 3 2 3 3 0 2 3 0 2 1 3 1 2 3 2 0 0 3 0 1 2 3 0 0\n     0 0 2 0 1 0 2 1 1 1 2 0]</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-39",
      "source": [
        "alphas = np.logspace(-1,1,200)\n",
        "\n",
        "cumulated_r2 = np.zeros( alphas.shape )\n",
        "\n",
        "\n",
        "fig,ax = plt.subplots(figsize = (10,5))\n",
        "\n",
        "\n",
        "for fold in range(k):\n",
        "\n",
        "    X_valid = X[ I==fold , :]\n",
        "    y_valid = y[I==fold]\n",
        "\n",
        "    # we will use the rest to train the model\n",
        "    X_train = X[ I!=fold , :]\n",
        "    y_train = y[I!=fold]\n",
        "\n",
        "    r2 = testAlphas( X_train , y_train , X_valid , y_valid , alphas)\n",
        "    cumulated_r2 += r2\n",
        "\n",
        "\n",
        "    ax.plot( np.log10(alphas) , r2 , label = 'fold '+str(fold) , linestyle='dotted' )\n",
        "\n",
        "## cross-validated r2 is the average across each fold:\n",
        "cross_valid_r2 = cumulated_r2 / k\n",
        "\n",
        "bestI = np.argmax(cross_valid_r2)\n",
        "bestLogAlpha = np.log10( alphas[bestI] )\n",
        "bestR2_valid = cross_valid_r2[bestI]\n",
        "\n",
        "ax.plot( np.log10(alphas), cross_valid_r2 , label='cross-validated r2' )\n",
        "ax.scatter( [bestLogAlpha] , [bestR2_valid]  , c='red')\n",
        "ax.set_xlabel(\"log10( alpha )\")\n",
        "ax.set_ylabel(\"R2\")\n",
        "ax.set_ylim(-0.1,1.1)\n",
        "ax.legend()\n",
        "\n",
        "fig.suptitle(\"best alpha : {:.2f} - cross-validated R2 : {:.2f}\".format(10**bestLogAlpha , bestR2_valid))"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-40",
      "source": "<!--<a href=\"output_41_1.png\" rel=\"noopener noreferrer\"><img src=\"output_41_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>There, you can realize that now, for each possible value of our hyper-parameter we fit and evaluate not 1, but &#36;k&#36; models, here 4.</p>\n<p>So, for 200 values of &#36;\\alpha&#36;, that means 200x4 = 800 models to fit and evaluate.</p>\n<p>Now, consider that we have other hyper-parameters, such as the type of regularization (L1 or L2),\nor the degree of the polynomial we consider, and now you understand why Machine Learning can quickly become  computationnaly intensive.</p>\n<p>Finally, here is the proposed strategy as aschematic, just to reiterate</p>\n<!--<a href=\"image/Presentation2.png\" rel=\"noopener noreferrer\"><img src=\"image/Presentation2.png\"  alt=\"presentation2. \"   loading=\"lazy\"></a>-->\n<p>For those kind of methods to work, since we are solicitting our dataset many times, you need to have quite a lot of points. Typically the number of points for our sparrow disturbance is too small to perform nicely this procedure.</p>\n<h1 id=\"ols-and-glm-regression-with-the-classical-ml-pipeline\">OLS and GLM regression with the classical ML pipeline</h1>\n<h2 id=\"classical-ml-pipeline-ols-regression\">classical ML pipeline OLS regression</h2>\n<p>Let’s come back to the diabetes dataset:</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-41",
      "source": [
        "df_diabetes.head()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-42",
      "source": "\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-43",
      "source": [
        "diabetes['target'][:5]"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-44",
      "source": "<p>array([151.,  75., 141., 206., 135.])</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-45",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#always split your dataset and do the fitting on the training\n",
        "# the train_test_split will split the data into train and test set\n",
        "# let's keep 25% of the data aside for the final test\n",
        "X_diabetes_train, X_diabetes_test, y_diabetes_train, y_diabetes_test = train_test_split(df_diabetes,\n",
        "                                                                                        diabetes['target'],\n",
        "                                                                                        test_size = 0.25,\n",
        "                                                                                        random_state=1425)\n",
        "print('train set size', len(y_diabetes_train))\n",
        "print('test  set size', len(y_diabetes_test ))"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-46",
      "source": "<p>train set size 331\n    test  set size 111</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-47",
      "source": [
        "%%time\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# while not strictly necessary for this dataset,\n",
        "# regression model normally need the X values to be properly scaled.\n",
        "# this is something that was done under the hood by statsmodels, but with sklearn\n",
        "# we have to handle it explicitely.\n",
        "#\n",
        "# NB : in that particular dataset the data is already scaled,\n",
        "#      but we wanted to show this important step anyway\n",
        "\n",
        "# in our model we will also consider polynomials for our features,\n",
        "# the PolynomialFeatures object generates all polynomials of a given degree for us\n",
        "\n",
        "\n",
        "pipeline_reg_diabetes=Pipeline([('scalar',StandardScaler()),\n",
        "                                ('poly',PolynomialFeatures(include_bias=False)),\n",
        "                                ('model',SGDRegressor())])\n",
        "\n",
        "\n",
        "\n",
        "# define the hyperparameters you want to test\n",
        "# with the range over which you want it to be tested.\n",
        "# Here the hyperparamters\n",
        "#   * the degree of the polynomials\n",
        "#   * the form of regularization : l1 or l2\n",
        "#   * the strength of regularization : alpha\n",
        "grid_values = {'poly__degree': np.arange(1,4,1),\n",
        "               'model__penalty':['l1','l2'],\n",
        "               'model__alpha':np.logspace(-1,1,100)}\n",
        "\n",
        "\n",
        "#Feed the pipeline and set of values to the GridSearchCV with the\n",
        "# score over which the decision should be taken (ir R^2).\n",
        "# and the cross-validation scheme, here the number of fold in a stratified k-fold strategy\n",
        "grid_reg_diabetes_r2 = GridSearchCV(pipeline_reg_diabetes,\n",
        "                                    param_grid = grid_values,\n",
        "                                    scoring='r2',\n",
        "                                    cv = 5,\n",
        "                                    n_jobs=-1)\n",
        "\n",
        "# Where the actual fit happens\n",
        "#  the gridSearchCV object will go through each hyperparameter value combination\n",
        "#  and fit + evaluate each fold, and averages the score across each fold\n",
        "#\n",
        "#  it then finds the combination that gave the best score and\n",
        "#  use it to re-train a model with the whole train data\n",
        "grid_reg_diabetes_r2.fit(X_diabetes_train, y_diabetes_train)\n",
        "\n",
        "#get the best cross-validated score\n",
        "print('Grid best score ('+grid_reg_diabetes_r2.scoring+'): ',\n",
        "      grid_reg_diabetes_r2.best_score_)\n",
        "# print the best parameters\n",
        "print('Grid best parameter :')\n",
        "for k,v in grid_reg_diabetes_r2.best_params_.items():\n",
        "    print(' {:>20} : {}'.format(k,v))\n",
        "\n",
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-48",
      "source": "<p>Grid best score (r2):  0.4850203038301172\n    Grid best parameter :\n             model__alpha : 4.5348785081285845\n           model__penalty : l1\n             poly__degree : 2\n    CPU times: user 1.8 s, sys: 112 ms, total: 1.92 s\n    Wall time: 5.5 s</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-49",
      "source": [
        "# get the equivalent score on the test set\n",
        "y_diabetes_decision_fn_scores_r2=grid_reg_diabetes_r2.score(X_diabetes_test,\n",
        "                                                            y_diabetes_test)\n",
        "\n",
        "print('Grid best parameter (max. '+grid_reg_diabetes_r2.scoring+') model on test: ',\n",
        "      y_diabetes_decision_fn_scores_r2)\n",
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-50",
      "source": "<p>Grid best parameter (max. r2) model on test:  0.46179242410993626</p>\n<p>One can also access the best model parameter:</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-51",
      "source": [
        "# here is a recipe to get the name of the features, with their power\n",
        "\n",
        "best_reg = grid_reg_diabetes_r2.best_estimator_['model']\n",
        "poly     = grid_reg_diabetes_r2.best_estimator_['poly']\n",
        "\n",
        "coef_names = ['_'.join([df_diabetes.columns[j]+'^'+str(poly.powers_[i][j])for j in range(len(df_diabetes.columns)) if poly.powers_[i][j]>0]) for i in range(len(poly.powers_)) ]\n",
        "\n",
        "sorted_features=sorted( [(coef_names[i],abs(best_reg.coef_[i])) for i in range(len(poly.powers_))] ,\n",
        "                       key=itemgetter(1),reverse=True)\n",
        "\n",
        "print('Important features')\n",
        "\n",
        "for feature, weight in sorted_features:\n",
        "    print('\\t{:>10}\\t{:.3f}'.format(feature,weight) )"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-52",
      "source": "<p>Important features\n             sex^2\t38.439\n             bmi^1\t22.800\n              s5^1\t22.339\n              bp^1\t8.965\n              s3^1\t5.780\n              bp^2\t5.150\n             bmi^2\t4.432\n              s6^2\t3.717\n        age^1_sex^1\t3.686\n             age^2\t2.912\n             sex^1\t2.112\n              s1^2\t0.720\n             age^1\t0.000\n              s1^1\t0.000\n              s2^1\t0.000\n              s4^1\t0.000\n              s6^1\t0.000\n        age^1_bmi^1\t0.000\n        age^1_bp^1\t0.000\n        age^1_s1^1\t0.000\n        age^1_s2^1\t0.000\n        age^1_s3^1\t0.000\n        age^1_s4^1\t0.000\n        age^1_s5^1\t0.000\n        age^1_s6^1\t0.000\n        sex^1_bmi^1\t0.000\n        sex^1_bp^1\t0.000\n        sex^1_s1^1\t0.000\n        sex^1_s2^1\t0.000\n        sex^1_s3^1\t0.000\n        sex^1_s4^1\t0.000\n        sex^1_s5^1\t0.000\n        sex^1_s6^1\t0.000\n        bmi^1_bp^1\t0.000\n        bmi^1_s1^1\t0.000\n        bmi^1_s2^1\t0.000\n        bmi^1_s3^1\t0.000\n        bmi^1_s4^1\t0.000\n        bmi^1_s5^1\t0.000\n        bmi^1_s6^1\t0.000\n         bp^1_s1^1\t0.000\n         bp^1_s2^1\t0.000\n         bp^1_s3^1\t0.000\n         bp^1_s4^1\t0.000\n         bp^1_s5^1\t0.000\n         bp^1_s6^1\t0.000\n         s1^1_s2^1\t0.000\n         s1^1_s3^1\t0.000\n         s1^1_s4^1\t0.000\n         s1^1_s5^1\t0.000\n         s1^1_s6^1\t0.000\n              s2^2\t0.000\n         s2^1_s3^1\t0.000\n         s2^1_s4^1\t0.000\n         s2^1_s5^1\t0.000\n         s2^1_s6^1\t0.000\n              s3^2\t0.000\n         s3^1_s4^1\t0.000\n         s3^1_s5^1\t0.000\n         s3^1_s6^1\t0.000\n              s4^2\t0.000\n         s4^1_s5^1\t0.000\n         s4^1_s6^1\t0.000\n              s5^2\t0.000\n         s5^1_s6^1\t0.000</p>\n<p>And we can plot the model prediction against the data:</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-53",
      "source": [
        "## train prediction\n",
        "y_diabetes_train_pred = grid_reg_diabetes_r2.predict(X_diabetes_train)\n",
        "## test prediction\n",
        "y_diabetes_test_pred  = grid_reg_diabetes_r2.predict(X_diabetes_test)\n",
        "\n",
        "\n",
        "plt.scatter( y_diabetes_train_pred , y_diabetes_train , c=\"blue\" , label='train set'  )\n",
        "plt.scatter( y_diabetes_test_pred , y_diabetes_test , c=\"red\" , label='test set'  )\n",
        "m,M = min(y_diabetes_train_pred) , max(y_diabetes_train_pred)\n",
        "plt.plot( [m,M] , [m,M] , 'k--' )\n",
        "plt.xlabel( 'predicted values' )\n",
        "plt.ylabel( 'real values' )\n",
        "plt.legend()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-54",
      "source": "<!--<a href=\"output_52_1.png\" rel=\"noopener noreferrer\"><img src=\"output_52_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-55",
      "source": [
        "grid_reg_diabetes_r2.best_estimator_['scalar']"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-56",
      "source": "<h2 id=\"a-toy-model-to-visualize-logistic-regression\">A toy model to visualize logistic regression.</h2>\n<p>Let’s imagine a simple case with 2 groups, and a single feature:</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-57",
      "source": [
        "X1 = np.concatenate( [ np.random.randn(300) , np.random.randn(300)+4 ])\n",
        "y = np.array( [0]*300 + [1]*300 )\n",
        "\n",
        "sns.histplot( x=X1,hue = y )"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-58",
      "source": "<!--<a href=\"output_55_1.png\" rel=\"noopener noreferrer\"><img src=\"output_55_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>We will use a logistic regression to model the relationship between the class and the feature.</p>\n<p>Remember : <strong>Logistic regression does not model the class directly, but rather model the class probabilities</strong> (through the logit transform)</p>\n<p>Let’s see how regularization affect the class probabilities found by our model:</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-59",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# do not forget to scale the data\n",
        "X1_norm = StandardScaler().fit_transform(X1.reshape( X1.shape[0] , 1 ))\n",
        "\n",
        "fig,ax = plt.subplots( figsize = (10,5) )\n",
        "\n",
        "ax.scatter( X1_norm , y , c = y )\n",
        "\n",
        "for alpha in [0.01,0.1,1,10]:\n",
        "\n",
        "    # this implementation does not take alpha but rather C = 1/alpha\n",
        "    C = 1/alpha\n",
        "    lr = LogisticRegression( penalty = 'l2' , C = C )\n",
        "    lr.fit(X1_norm , y)\n",
        "\n",
        "    proba = lr.predict_proba(np.linspace(-2,2,100).reshape(-1, 1))\n",
        "    ax.plot( np.linspace(-2,2,100) , proba[:,1] , label = 'alpha = {}'.format(alpha) )\n",
        "ax.legend()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-60",
      "source": "<!--<a href=\"output_57_1.png\" rel=\"noopener noreferrer\"><img src=\"output_57_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>We can see that <strong>when &#36;\\alpha&#36; grows the probabilities evolve more smoothly</strong> ie. we have more regularization.</p>\n<blockquote class=\"comment\" style=\"border: 2px solid #ffecc1; margin: 1em 0.2em\">\n<div class=\"box-title comment-title\" id=\"comment-2\"><i class=\"far fa-comment-dots\" aria-hidden=\"true\" ></i> Comment</div>\n<p>However, note that all the curves meet at the same point, corresponding to the 0.5 probability.</p>\n</blockquote>\n<p>This is nice, but <strong>our end-goal is to actually be able to predict the classes</strong>, and not just the probabilities.</p>\n<p>Our task is not regression anymore, but rather <strong>classification</strong>.</p>\n<p>So here, we do not evaluate the model using &#36;R^2&#36; or log-likelihood, but a classification metric.</p>\n<p>we will discuss a few of these metrics, and we will begin by the most common: <strong>Accuracy</strong></p>\n<p>The Accuracy is the proportion of samples which were correctly classified (as either category).</p>\n<p>More mathematically:</p>\n\n\\[Accuracy = \\frac{TP + TN}{TP+FP+FN+TN}\\]\n<!--<a href=\"image/TPFP.png\" rel=\"noopener noreferrer\"><img src=\"image/TPFP.png\"  alt=\"image/TPFP.png. \"   loading=\"lazy\"></a>-->\n<p>Image credit wikipedia user Sharpr for svg version. original work by kakau in a png. Licensed under the <a href=\"https://creativecommons.org/licenses/by-sa/3.0/deed.en\">Creative Commons Attribution-Share Alike 3.0 Unported license</a>.</p>\n<ul>\n<li>TP : True Positive</li>\n<li>FP : False Positive</li>\n<li>TN : True Negative</li>\n<li>FN : False Negative</li>\n</ul>\n<p>So you can see that accuracy forces us to make a choice about the <strong>probability threshold we use predict categories</strong>.</p>\n<p>0.5 is a common choice, and the default of the <code style=\"color: inherit\">predict</code> method:</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-61",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_predicted = lr.predict(X1_norm)\n",
        "\n",
        "print( f\"Accuracy with a threshold of 0.5 : {accuracy_score(y,y_predicted):.2f}\"  )\n",
        "\n",
        "pd.crosstab( y , y_predicted )"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-62",
      "source": "<p>Accuracy with a threshold of 0.5 : 0.98</p>\n<div>\n<style scoped=\"\">\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n<thead>\n<tr style=\"text-align: right;\">\n<th>col_0</th>\n<th>0</th>\n<th>1</th>\n</tr>\n<tr>\n<th>row_0</th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<th>0</th>\n<td>292</td>\n<td>8</td>\n</tr>\n<tr>\n<th>1</th>\n<td>5</td>\n<td>295</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>But it can be useful to remember that this is only 1 choice among many:</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-63",
      "source": [
        "threshold = 0.2\n",
        "y_predicted = lr.predict_proba(X1_norm)[:,1] > threshold\n",
        "print( f\"Accuracy with a threshold of {threshold} : {accuracy_score(y,y_predicted):.2f}\"  )\n",
        "pd.crosstab( y , y_predicted )"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-64",
      "source": "<p><strong>Micro-exercise :</strong> modify the threhold in the code above.</p>\n<ul>\n<li>in which direction should the threshold move to limit the number of False Positive ?</li>\n<li>for which application could that be useful ?</li>\n</ul>\n<h2 id=\"classical-ml-pipeline-logistic-regression\">classical ML pipeline logistic regression</h2>\n<p>Let’s build a logistic regression model that will be able to predict if a breast tumor is malignant or not</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-65",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "#loading the dataset which is comprised in scikit learn already\n",
        "data = load_breast_cancer()\n",
        "\n",
        "## we reduce the features because otherwise this problem is a bit too easy ;-)\n",
        "m = list( map( lambda x : x.startswith(\"mean \") , data[\"feature_names\"] ) )\n",
        "\n",
        "\n",
        "X_cancer=data['data'][:,m]\n",
        "y_cancer= 1-data['target']\n",
        "\n",
        "#making it into a dataframe\n",
        "breast_cancer_df=pd.DataFrame(X_cancer,\n",
        "    columns=data[\"feature_names\"][m])\n",
        "\n",
        "breast_cancer_df[\"target\"]=y_cancer\n",
        "\n",
        "breast_cancer_df.head()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-66",
      "source": "\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-67",
      "source": [
        "breast_cancer_df.target.value_counts()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-68",
      "source": "<p>target\n    0    357\n    1    212\n    Name: count, dtype: int64</p>\n<ul>\n<li>357 benign samples</li>\n<li>212 malignant samples</li>\n</ul>\n<p>Here, all these covariables / features are defined on very different scales, for them to be treated fairly in their comparison you need to take that into account by scaling.</p>\n<p>But first, let’s split the model into a train and a test dataset:</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-69",
      "source": [
        "#split your data\n",
        "\n",
        "# stratify is here to make sure that you split keeping the repartition of labels unaffected\n",
        "X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test_split(X_cancer,\n",
        "                                                                                y_cancer,\n",
        "                                                                                random_state=0,\n",
        "                                                                                stratify=y_cancer)\n",
        "\n",
        "\n",
        "print(\"fraction of class malignant in train\",sum(y_train_cancer)/len(y_train_cancer))\n",
        "print(\"fraction of class malignant in test \",sum(y_test_cancer)/len(y_test_cancer) )\n",
        "print(\"fraction of class malignant in full \",sum(y_cancer)/len(y_cancer))"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-70",
      "source": "<p>fraction of class malignant in train 0.3732394366197183\n    fraction of class malignant in test  0.3706293706293706\n    fraction of class malignant in full  0.37258347978910367</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-71",
      "source": [
        "%%time\n",
        "## create the pipeline of data handling :\n",
        "## scaling, then logistic regression\n",
        "\n",
        "## in order for the LogisticRegression object takes solver=\"liblinear\" argument\n",
        "## in order to be able to test the l1 and l2 norm\n",
        "## other solver exists, and are more or less performant / have different capabilities\n",
        "pipeline_lr_cancer=Pipeline([('scaler',StandardScaler()),\n",
        "                             ('model',LogisticRegression(solver = 'liblinear'))])\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "grid_values = {'model__C': np.logspace(-5,2,100),\n",
        "               'model__penalty':['l1','l2']}\n",
        "\n",
        "grid_lr_cancer_acc = GridSearchCV(pipeline_lr_cancer,\n",
        "                                  param_grid = grid_values,\n",
        "                                  scoring='accuracy',\n",
        "                                  cv=5,\n",
        "                                  n_jobs=-1)\n",
        "\n",
        "grid_lr_cancer_acc.fit(X_train_cancer, y_train_cancer)#train your pipeline\n",
        "\n",
        "#get the best cross-validated score\n",
        "print('Grid best score ('+grid_lr_cancer_acc.scoring+'): ',\n",
        "      grid_lr_cancer_acc.best_score_)\n",
        "# print the best parameters\n",
        "print('Grid best parameter :')\n",
        "for k,v in grid_lr_cancer_acc.best_params_.items():\n",
        "    print(' {:>20} : {}'.format(k,v))\n",
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-72",
      "source": "<p>Grid best score (accuracy):  0.9436935704514363\n    Grid best parameter :\n                 model__C : 0.0210490414451202\n           model__penalty : l2\n    CPU times: user 390 ms, sys: 4.67 ms, total: 394 ms\n    Wall time: 686 ms</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-73",
      "source": [
        "1/0.02"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-74",
      "source": "<p>50.0</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-75",
      "source": [
        "# calculate the score of your trained pipeline on the test\n",
        "cancer_acc = grid_lr_cancer_acc.score(X_test_cancer,y_test_cancer)\n",
        "print('Grid best parameter (max.'+grid_lr_cancer_acc.scoring+') model on test: ',\n",
        "      cancer_acc)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-76",
      "source": "<p>Grid best parameter (max.accuracy) model on test:  0.9370629370629371</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-77",
      "source": [
        "y_test_cancer.shape"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-78",
      "source": "<p>(143,)</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-79",
      "source": [
        "# we can then access the coefficient of the model, to assess the importance of the different parameters:\n",
        "\n",
        "w_lr_cancer=grid_lr_cancer_acc.best_estimator_['model'].coef_[0]\n",
        "\n",
        "sorted_features=sorted( zip( breast_cancer_df.columns , np.abs( w_lr_cancer ) ),\n",
        "                       key=itemgetter(1),\n",
        "                       reverse=True)\n",
        "\n",
        "print('Features sorted per importance in discriminative process')\n",
        "for f,ww in sorted_features:\n",
        "    print('{:>25}\\t{:.3f}'.format(f,ww))"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-80",
      "source": "<p>Features sorted per importance in discriminative process\n          mean concave points\t0.497\n                  mean radius\t0.442\n               mean perimeter\t0.441\n                    mean area\t0.422\n               mean concavity\t0.399\n                 mean texture\t0.373\n             mean compactness\t0.295\n              mean smoothness\t0.264\n                mean symmetry\t0.183\n       mean fractal dimension\t0.070</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-81",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "y_cancer_test_pred = grid_lr_cancer_acc.predict(X_test_cancer)\n",
        "\n",
        "# get the confusion matrix:\n",
        "confusion_m_cancer = confusion_matrix(y_test_cancer, y_cancer_test_pred)\n",
        "\n",
        "## recipe to plot the confusion matrix :\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(confusion_m_cancer, annot=True)\n",
        "plt.title('Accuracy:{0:.3f}'.format(accuracy_score(y_test_cancer,y_cancer_test_pred)))\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-82",
      "source": "<!--<a href=\"output_76_1.png\" rel=\"noopener noreferrer\"><img src=\"output_76_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>So, with its default threshold of 0.5, this model tends to produce more False Positive (ie. benign cancer seen as malignant), than False Negative (ie. malignant cancer seen as benign).</p>\n<p>Depending on the particular of the problem we are trying to solve, that may be a desirable outcome.</p>\n<p>Whatever the case, it is always interesting to explore a bit more : we will plot how each possible threshold affect the True Positive Rate and the False Positive Rate (<strong>TPR and FPR</strong>) : this is the Receiver Operating Characteristic c urve (<strong>ROC curve</strong>)</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-83",
      "source": [
        "from scipy.special import expit\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "# 1. the decision_function gives you the \"score\" for a point to be in a class\n",
        "y_score_lr_cancer = grid_lr_cancer_acc.decision_function(X_test_cancer)\n",
        "\n",
        "#   for the logistic regression, that score is the logit, so can convert it back to\n",
        "#   probabilities with the expit function (which is the inverse of the logit)\n",
        "y_proba_lr_cancer = expit(y_score_lr_cancer )\n",
        "\n",
        "# 2. this calculates the ROC curve : TPR and FPR for each threshold of score\n",
        "fpr_lr_cancer, tpr_lr_cancer, threshold_cancer = roc_curve(y_test_cancer, y_proba_lr_cancer)\n",
        "\n",
        "# we find the point corresponding to a 0.5 theshold\n",
        "keep = np.argmin( np.abs( threshold_cancer - 0.5 ) )\n",
        "\n",
        "# we compute the area under the ROC curve\n",
        "roc_auc_lr_cancer = auc( fpr_lr_cancer, tpr_lr_cancer )\n",
        "\n",
        "# 3. plotting\n",
        "plt.figure()\n",
        "plt.xlim([-0.01, 1.01])\n",
        "plt.ylim([-0.01, 1.01])\n",
        "plt.plot(fpr_lr_cancer, tpr_lr_cancer, lw=3, label='LogRegr ROC curve\\n (area = {:0.2f})'.format(roc_auc_lr_cancer))\n",
        "plt.plot(fpr_lr_cancer[keep], tpr_lr_cancer[keep],'ro',label='threshold=0.5')\n",
        "plt.xlabel('False Positive Rate', fontsize=16)\n",
        "plt.ylabel('True Positive Rate', fontsize=16)\n",
        "plt.title('ROC curve (logistic classifier)', fontsize=16)\n",
        "plt.legend(loc='lower right', fontsize=13)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-84",
      "source": "<!--<a href=\"output_78_0.png\" rel=\"noopener noreferrer\"><img src=\"output_78_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>So with this ROC curve, we can see how the model would behave on different thresholds.</p>\n<p><strong>Question:</strong> we have marked the 0.5 threshold on the plot. Where would a higher threshold be on the curve?</p>\n<p>You can see that when plotting the ROC curve, I have also computed its “Area Under the Curve” :\nindeed ROC AUC is another common metric when doing classification.</p>\n<p>For now, let’s put this aside briefly to explore a very common problem in classification : imbalance</p>\n<h2 id=\"imbalanced-dataset\">Imbalanced dataset</h2>\n<p>Let’s use the same small example as before, but now instead of 300 sample of each class, imagine we only have 30 of class 1:</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-85",
      "source": [
        "X1 = np.concatenate( [ np.random.randn(300) , np.random.randn(30)+2 ])\n",
        "y = np.array( [0]*300 + [1]*30 )\n",
        "\n",
        "# do not forget to scale the data\n",
        "X1_norm = StandardScaler().fit_transform(X1.reshape( X1.shape[0] , 1 ))\n",
        "\n",
        "fig,ax = plt.subplots(1,2, figsize = (14,5) )\n",
        "\n",
        "sns.histplot( x=X1,hue = y , ax =ax [0])\n",
        "\n",
        "\n",
        "ax[1].scatter( X1_norm , y , c = y )\n",
        "\n",
        "for alpha in [0.01,0.1,1,10]:\n",
        "\n",
        "    # this implementation does not take alpham but rather C = 1/alpha\n",
        "    C = 1/alpha\n",
        "    lr = LogisticRegression( penalty = 'l2' , C = C )\n",
        "    lr.fit(X1_norm , y)\n",
        "\n",
        "    proba = lr.predict_proba(np.linspace(-2,3,100).reshape(-1, 1))\n",
        "    ax[1].plot( np.linspace(-2,3,100) , proba[:,1] , label = 'alpha = {}'.format(alpha) )\n",
        "ax[1].legend()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-86",
      "source": "<!--<a href=\"output_82_1.png\" rel=\"noopener noreferrer\"><img src=\"output_82_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>You can see that now the point where the probability curves for different alpha converge is not 0.5 anymore…</p>\n<p>Also, the probability says fairly low even at the right end of the plot.</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-87",
      "source": [
        "y_predicted = lr.predict(X1_norm)\n",
        "print( f\"Accuracy with a threshold of 0.5 : {accuracy_score(y,y_predicted):.2f}\"  )\n",
        "pd.crosstab( y , y_predicted )"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-88",
      "source": "<p>Accuracy with a threshold of 0.5 : 0.92</p>\n<div>\n<style scoped=\"\">\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n<thead>\n<tr style=\"text-align: right;\">\n<th>col_0</th>\n<th>0</th>\n<th>1</th>\n</tr>\n<tr>\n<th>row_0</th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<th>0</th>\n<td>298</td>\n<td>2</td>\n</tr>\n<tr>\n<th>1</th>\n<td>25</td>\n<td>5</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>So, most of the class 1 samples are miss-classified (22/30), but we still get a very high accuracy…</p>\n<p>That is because, by contruction, both the <strong>logistic regression and accuracy score do not differentiate False Positive and False Negative</strong>.</p>\n<p>And the problem gets worse the more imbalance there is :</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-89",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "\n",
        "## RECALL = TP / (TP + FN)\n",
        "\n",
        "recall_list = []\n",
        "acc_list = []\n",
        "\n",
        "imbalance_list = np.linspace(0,1,50)\n",
        "\n",
        "alpha = 1\n",
        "for imbalance in imbalance_list:\n",
        "\n",
        "    n0 = 300\n",
        "    n1 = int( n0 * (1 - imbalance) )\n",
        "    if n1 == 0:\n",
        "        n1 = 1\n",
        "\n",
        "    X1 = np.concatenate( [ np.random.randn(n0) , np.random.randn(n1)+2 ])\n",
        "    y = np.array( [0]*n0 + [1]*n1 )\n",
        "\n",
        "    X1_norm = StandardScaler().fit_transform(X1.reshape( X1.shape[0] , 1 ))\n",
        "\n",
        "    C = 1/alpha\n",
        "    lr = LogisticRegression( penalty = 'l2' , C = C )\n",
        "    lr.fit(X1_norm , y)\n",
        "\n",
        "    y_predicted = lr.predict(X1_norm)\n",
        "\n",
        "    recall_list.append( recall_score( y , y_predicted ) )\n",
        "    acc_list.append( accuracy_score(y,y_predicted) )\n",
        "\n",
        "\n",
        "fig,ax=plt.subplots(figsize = (10,4))\n",
        "ax.plot( imbalance_list , acc_list , label='accuracy' )\n",
        "ax.plot( imbalance_list , recall_list , label='recall' )\n",
        "ax.set_xlabel(\"imbalance\")\n",
        "ax.legend()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-90",
      "source": "<!--<a href=\"output_86_1.png\" rel=\"noopener noreferrer\"><img src=\"output_86_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>So not only does the precision get worse, the <strong>accuracy actually gets higher as there is more imbalance!</strong></p>\n<p>So the problem here may be 2-fold:</p>\n<ul>\n<li>imbalance in our dataset skews the <strong>logistic regression</strong> toward a particular outcome</li>\n<li><strong>accuracy</strong> is not able to differenciate between False Positive and False Negative, and so it is <strong>blind to imbalance</strong></li>\n</ul>\n<p>Consequently, the solutions will have to come both from the model, and from the metric we are using.</p>\n<p><strong>For the logistic regression</strong>:</p>\n<ul>\n<li>we will re-weight sample according to their class frequency, so that they are more important during the fitting.</li>\n<li>in sklearn : <code style=\"color: inherit\">LogisticRegression( ... , class_weight='balanced')</code></li>\n</ul>\n<p><strong>For the metric</strong>, there exists several metrics which are sensitive to imbalance problems.\nHere we will introduce the <strong><a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#balanced-accuracy-score\">balanced accuracy</a></strong>:</p>\n\n\\[balanced\\\\_accuracy = 0.5*( \\frac{TP}{TP+FN} + \\frac{TN}{TN+FP} )\\]\n<blockquote class=\"comment\" style=\"border: 2px solid #ffecc1; margin: 1em 0.2em\">\n<div class=\"box-title comment-title\" id=\"comment-3\"><i class=\"far fa-comment-dots\" aria-hidden=\"true\" ></i> Comment</div>\n<p>Other scores you may want to look-up : <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score\">average-precision score</a>, and <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\">f1-score</a>, which are both linked to the precision/recall curve</p>\n</blockquote>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-91",
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "\n",
        "def check_imbalance_effect( imbalance_list , class_weight = None):\n",
        "\n",
        "    recall_list = []\n",
        "    balanced_acc_list = []\n",
        "    acc_list = []\n",
        "    for imbalance in imbalance_list:\n",
        "\n",
        "        n0 = 300\n",
        "        n1 = int( n0 * (1 - imbalance) )\n",
        "        if n1 == 0:\n",
        "            n1 = 1\n",
        "\n",
        "        X1 = np.concatenate( [ np.random.randn(n0) , np.random.randn(n1)+2 ])\n",
        "        y = np.array( [0]*n0 + [1]*n1 )\n",
        "\n",
        "        X1_norm = StandardScaler().fit_transform(X1.reshape( X1.shape[0] , 1 ))\n",
        "\n",
        "        # LR\n",
        "        lr = LogisticRegression( penalty = 'l2' , C = 1 , class_weight=class_weight)\n",
        "        lr.fit(X1_norm , y)\n",
        "\n",
        "        y_predicted = lr.predict(X1_norm)\n",
        "\n",
        "        recall_list.append( recall_score( y , y_predicted )  )\n",
        "        acc_list.append( accuracy_score(y,y_predicted) )\n",
        "        balanced_acc_list.append( balanced_accuracy_score(y,y_predicted) )\n",
        "\n",
        "    return recall_list , acc_list , balanced_acc_list"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-92",
      "source": "\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-93",
      "source": [
        "imbalance_list = np.linspace(0,1,50)\n",
        "\n",
        "### first, we see what happens without class_weight=None\n",
        "\n",
        "recall_list , acc_list , balanced_acc_list = check_imbalance_effect( imbalance_list ,\n",
        "                                                               class_weight = None)\n",
        "\n",
        "\n",
        "fig,ax=plt.subplots(1,2,figsize = (12,4))\n",
        "ax[0].plot( imbalance_list , acc_list , label='accuracy - class_weight=None' )\n",
        "ax[0].plot( imbalance_list , recall_list , label='recall - class_weight=None' )\n",
        "ax[0].plot( imbalance_list , balanced_acc_list , label='balanced_accuracy - class_weight=None' )\n",
        "ax[0].set_xlabel(\"imbalance\")\n",
        "ax[0].set_ylim(0,1)\n",
        "ax[0].legend()\n",
        "## now, with class weight\n",
        "\n",
        "recall_list , acc_list , balanced_acc_list = check_imbalance_effect( imbalance_list ,\n",
        "                                                               class_weight = 'balanced')\n",
        "\n",
        "ax[1].plot( imbalance_list , acc_list , label='accuracy - class_weight=balanced' )\n",
        "ax[1].plot( imbalance_list , recall_list , label='recall - class_weight=balanced' )\n",
        "ax[1].plot( imbalance_list , balanced_acc_list , label='balanced_accuracy - class_weight=balanced' )\n",
        "ax[1].set_xlabel(\"imbalance\")\n",
        "ax[1].set_ylim(0,1)\n",
        "ax[1].legend()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-94",
      "source": "<!--<a href=\"output_89_1.png\" rel=\"noopener noreferrer\"><img src=\"output_89_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>So, the <strong>balanced accuracy</strong> is able to detect an imbalance problem.</p>\n<p>Setting <code style=\"color: inherit\">class_weight='balanced'</code> in our logistic regression fixes the imbalance at the level of the model.</p>\n<p><strong>micro-exercise</strong>:  re-explore the hyper-parameters of the logisitic regression for the cancer data-set, but this time, account for the imbalance between malignant and benign samples.</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-95",
      "source": [
        "%%time\n",
        "## create the pipeline of data handling :\n",
        "## scaling, then logistic regression\n",
        "\n",
        "## in order for the LogisticRegression object takes solver=\"liblinear\" argument\n",
        "## in order to be able to test the l1 and l2 norm\n",
        "## other solver exists, and are more or less performant / have different capabilities\n",
        "pipeline_lr_cancer=Pipeline([('scaler',StandardScaler()),\n",
        "                             ('model',LogisticRegression(solver = 'liblinear' ))])\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "grid_values = {'model__C': np.logspace(-5,2,100),\n",
        "               'model__penalty':['l1','l2'],\n",
        "               'model__class_weight':[None,'balanced']}\n",
        "\n",
        "grid_lr_cancer_acc = GridSearchCV(pipeline_lr_cancer,\n",
        "                                  param_grid = grid_values,\n",
        "                                  scoring='balanced_accuracy',\n",
        "                                  cv=5,\n",
        "                                  n_jobs=-1)\n",
        "\n",
        "grid_lr_cancer_acc.fit(X_train_cancer, y_train_cancer)#train your pipeline\n",
        "\n",
        "#get the best cross-validated score\n",
        "print('Grid best score ('+grid_lr_cancer_acc.scoring+'): ',\n",
        "      grid_lr_cancer_acc.best_score_)\n",
        "# print the best parameters\n",
        "print('Grid best parameter :')\n",
        "for k,v in grid_lr_cancer_acc.best_params_.items():\n",
        "    print(' {:>20} : {}'.format(k,v))\n",
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-96",
      "source": "<p>Grid best score (balanced_accuracy):  0.9327313828588174\n    Grid best parameter :\n                 model__C : 0.09111627561154886\n      model__class_weight : balanced\n           model__penalty : l2\n    CPU times: user 722 ms, sys: 12.1 ms, total: 734 ms\n    Wall time: 1.41 s</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-97",
      "source": [
        "# calculate the score of your trained pipeline on the test\n",
        "cancer_acc = grid_lr_cancer_acc.score(X_test_cancer,y_test_cancer)\n",
        "print('Grid best parameter (max.'+grid_lr_cancer_acc.scoring+') model on test: ',\n",
        "      cancer_acc)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-98",
      "source": "<p>Grid best parameter (max.balanced_accuracy) model on test:  0.9105870020964361</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-99",
      "source": [
        "# we can then access the coefficient of the model, to assess the importance of the different parameters:\n",
        "\n",
        "w_lr_cancer=grid_lr_cancer_acc.best_estimator_['model'].coef_[0]\n",
        "\n",
        "sorted_features=sorted( zip( breast_cancer_df.columns , np.abs( w_lr_cancer ) ),\n",
        "                       key=itemgetter(1),\n",
        "                       reverse=True)\n",
        "\n",
        "print('Features sorted per importance in discriminative process')\n",
        "for f,ww in sorted_features:\n",
        "    print('{:>25}\\t{:.3f}'.format(f,ww))"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-100",
      "source": "<p>Features sorted per importance in discriminative process\n          mean concave points\t0.836\n                 mean texture\t0.733\n                  mean radius\t0.688\n               mean perimeter\t0.672\n                    mean area\t0.640\n               mean concavity\t0.577\n              mean smoothness\t0.511\n             mean compactness\t0.349\n                mean symmetry\t0.267\n       mean fractal dimension\t0.191</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-101",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "y_cancer_test_pred = grid_lr_cancer_acc.predict(X_test_cancer)\n",
        "\n",
        "# get the confusion matrix:\n",
        "confusion_m_cancer = confusion_matrix(y_test_cancer, y_cancer_test_pred)\n",
        "\n",
        "## recipe to plot the confusion matrix :\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(confusion_m_cancer, annot=True)\n",
        "plt.title('Accuracy:{0:.3f}'.format(accuracy_score(y_test_cancer,y_cancer_test_pred)))\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-102",
      "source": "<!--<a href=\"output_95_1.png\" rel=\"noopener noreferrer\"><img src=\"output_95_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>If you want to use a GLM other than the logistic regression:\n<a href=\"https://scikit-learn.org/stable/modules/linear_model.html#generalized-linear-regression\">GLM in sklearn</a></p>\n<h1 id=\"a-few-very-important-words-on-leakage\">A few VERY IMPORTANT words on leakage.</h1>\n<p>The most important part in all of the machine learning jobs that we have been presenting above, is that <strong>the data set on which you train and the data set on which you evaluate your model should be clearly separated</strong>(either the validation set when you do hyperparameter tunning, or test set for the final evaluation).</p>\n<p>No information directly coming from your test or your validation should pollute your train set. If it does you <strong>loose your ablity to have a meaningful evaluation power.</strong></p>\n<p>In general <strong>data leakage</strong> relates to every bits of information that you should not have access to in a real case scenario, being present in your training set.</p>\n<p>Among those examples of data leakage you could count :</p>\n<ul>\n<li><strong>using performance on the test set to decide which algorithm/hyperparameter to use</strong></li>\n<li>doing imputation or scaling before the train/test split</li>\n<li>inclusion of future data points in a time dependent or event dependent model.</li>\n</ul>\n<h1 id=\"exercise--logistic-regression\">Exercise : logistic regression</h1>\n<p>The framingham dataset links some patient features to their risk to develop a heart disease.</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-103",
      "source": [
        "df_heart=pd.read_csv('data/framingham.csv')\n",
        "\n",
        "df_heart.dropna(axis=0,inplace=True) # removing rows with NA values.\n",
        "\n",
        "print(df_heart.shape)\n",
        "df_heart.head()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-104",
      "source": "<p>(3658, 16)</p>\n<div>\n<style scoped=\"\">\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n<thead>\n<tr style=\"text-align: right;\">\n<th></th>\n<th>male</th>\n<th>age</th>\n<th>education</th>\n<th>currentSmoker</th>\n<th>cigsPerDay</th>\n<th>BPMeds</th>\n<th>prevalentStroke</th>\n<th>prevalentHyp</th>\n<th>diabetes</th>\n<th>totChol</th>\n<th>sysBP</th>\n<th>diaBP</th>\n<th>BMI</th>\n<th>heartRate</th>\n<th>glucose</th>\n<th>TenYearCHD</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<th>0</th>\n<td>1</td>\n<td>39</td>\n<td>4.0</td>\n<td>0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>195.0</td>\n<td>106.0</td>\n<td>70.0</td>\n<td>26.97</td>\n<td>80.0</td>\n<td>77.0</td>\n<td>0</td>\n</tr>\n<tr>\n<th>1</th>\n<td>0</td>\n<td>46</td>\n<td>2.0</td>\n<td>0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>250.0</td>\n<td>121.0</td>\n<td>81.0</td>\n<td>28.73</td>\n<td>95.0</td>\n<td>76.0</td>\n<td>0</td>\n</tr>\n<tr>\n<th>2</th>\n<td>1</td>\n<td>48</td>\n<td>1.0</td>\n<td>1</td>\n<td>20.0</td>\n<td>0.0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>245.0</td>\n<td>127.5</td>\n<td>80.0</td>\n<td>25.34</td>\n<td>75.0</td>\n<td>70.0</td>\n<td>0</td>\n</tr>\n<tr>\n<th>3</th>\n<td>0</td>\n<td>61</td>\n<td>3.0</td>\n<td>1</td>\n<td>30.0</td>\n<td>0.0</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n<td>225.0</td>\n<td>150.0</td>\n<td>95.0</td>\n<td>28.58</td>\n<td>65.0</td>\n<td>103.0</td>\n<td>1</td>\n</tr>\n<tr>\n<th>4</th>\n<td>0</td>\n<td>46</td>\n<td>3.0</td>\n<td>1</td>\n<td>23.0</td>\n<td>0.0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>285.0</td>\n<td>130.0</td>\n<td>84.0</td>\n<td>23.10</td>\n<td>85.0</td>\n<td>85.0</td>\n<td>0</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>Implement a logistic regression pipeline to predict the column <code style=\"color: inherit\">'TenYearCHD'</code> (dependent variable : ten year risk of coronary heart disease) by adapting some of the code above.</p>\n<p>Assess the performance of your model, and list the features by order of their importance.</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-105",
      "source": [
        "##separation in X and y\n",
        "X_heart = df_heart.drop( columns = \"TenYearCHD\" )\n",
        "y_heart = df_heart[ \"TenYearCHD\" ]\n",
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-106",
      "source": "\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-107",
      "source": [
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-108",
      "source": "<p>Solution - reading and setup data</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-109",
      "source": [
        "# %load -r -20 solutions/solution_03_01.py"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-110",
      "source": "<p>Solution - separate between train and test set</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-111",
      "source": [
        "# %load -r 22-30 solutions/solution_03_01.py"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-112",
      "source": "<p>Solution - pipeline creation and fitting</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-113",
      "source": [
        "# %load -r 32-50 solutions/solution_03_01.py"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-114",
      "source": "<p>Solution - evaluation on the test set</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-115",
      "source": [
        "# %load -r 51-71 solutions/solution_03_01.py"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-116",
      "source": "<p>Solution - plotting the ROC curve</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-117",
      "source": [
        "# %load -r 72-96 solutions/solution_03_01.py"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-118",
      "source": "<p>Solution - getting feature importance</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-119",
      "source": [
        "# %load -r 97- solutions/solution_03_01.py"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-120",
      "source": "<h1 id=\"support-vector-machine\">Support Vector Machine</h1>\n<h2 id=\"svm-for-classification\">SVM for Classification</h2>\n<h3 id=\"introduction\">introduction</h3>\n<p>“The basic principle of SVM is pretty simple. SVM aims at finding the ‘good’ threshold (hyperplane) to separate data from different classes. Conceptually it is very different from logistic regression where you maximize the log likelihood of the log odds function. <strong>With SVM you really look for an hyperplane that separates data and that’s it : there is no underlying hypothesis about probability distribution or anything else. It is very geometrical.</strong></p>\n<p>So what’s a good threshold? Again it is going to depend on the metric you are interested in. But at least a good threshold should be linked to this biais variance trade off in the sense that it should offer flexibility to your model.</p>\n<p>You can imagine that there is a quite a lot of hyperplanes separating data in your training set. You could stick your threshold right where the class 0 point closest to class 1 lies. But in that case it will be very far from the other class 0 points, which can be a problem. <strong>You could decide that your threshold should be right between the two closest extreme of your classes but that is going to be very sensitive to missclassified data or extreme events… Those points choosen as a reference to put your threshold are called support vectors.</strong></p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-121",
      "source": [
        "np.random.seed(10815657)\n",
        "\n",
        "\n",
        "fig,ax = plt.subplots(1,2,figsize=(15,7))\n",
        "\n",
        "# case 1\n",
        "norm1=0.2*np.random.randn(100)-2\n",
        "norm2=0.8*np.random.randn(100)+2.5\n",
        "ax[0].plot(norm1,[1]*100,'ro',markersize=10)\n",
        "ax[0].plot(norm2,[1]*100,'bo')\n",
        "\n",
        "min2 = min( norm2 )\n",
        "max1 = max( norm1 )\n",
        "\n",
        "ax[0].axvline(min2, color='k', linestyle='--', label='defined by the most extreme blue point')\n",
        "ax[0].axvline( (min2+max1)/2,color='k',linestyle='-.',label='middle of extreme of two classes')\n",
        "ax[0].legend(loc='best')\n",
        "\n",
        "\n",
        "# case 2\n",
        "cauch=0.8*np.random.standard_cauchy(10)-2\n",
        "norm=1*np.random.randn(100)+2.5\n",
        "\n",
        "ax[1].plot(cauch,[1]*10,'ro',markersize=10)\n",
        "ax[1].plot(norm,[1]*100,'bo')\n",
        "\n",
        "min2 = min( norm )\n",
        "max1 = max( cauch )\n",
        "\n",
        "ax[1].axvline(min2, color='k', linestyle='--', label='defined by the most extreme blue point')\n",
        "ax[1].axvline( (min2+max1)/2,color='k',linestyle='-.',label='middle of extreme of two classes')\n",
        "ax[1].legend(loc='best')\n",
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-122",
      "source": "<!--<a href=\"output_122_1.png\" rel=\"noopener noreferrer\"><img src=\"output_122_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>On the left panel, the two hyperplanes are valid separation but you can imagine that the plane defined by the most extreme blue point doesn’t leave much space for generalization</p>\n<p>If your data are not linearly separable, like in the right panel, you need to be able to choose support vectors that are going to do some misclassification but for the greater good.</p>\n<p>So, once again, you are confronted to a compromise. You should place your threshold somwhere that is globally best even though that would mean some miss-classification. We are back to our regularization problem and of course <strong>Support vector machine has a regularization parameter : C</strong>. The game now becomes placing your threshold right in the middle of points (support vectors) from  each classes that you have \"chosen\" to be general points for decision making : <strong>they don’t need to be the two closest points from different classes anymore. They need to be points where your hyperplane makes the least error differentiating classes.</strong></p>\n<!--<a href=\"image/1920px-SVM_margin.png\" rel=\"noopener noreferrer\"><img src=\"image/1920px-SVM_margin.png\"  alt=\"svm. \"   loading=\"lazy\"></a>-->\n<p>Image source : image by wikipedia user Larhmam, distributed under a <a href=\"https://creativecommons.org/licenses/by-sa/4.0/deed.en\">CC BY-SA 4.0 license</a>.</p>\n<table>\n<tbody>\n<tr>\n<td>So you want to maximize the margin separating the two classes. This margin is &#36;\\frac{2}{</td>\n<td> </td>\n<td>\\pmb{w}</td>\n<td> </td>\n<td>}&#36;. So you want to minimize &#36;</td>\n<td> </td>\n<td>\\pmb{w}</td>\n<td> </td>\n<td>&#36;. The SVM loss function we want to minimize with respect to &#36;\\pmb{w}&#36; and &#36;b&#36; is:</td>\n</tr>\n</tbody>\n</table>\n<p>&#36;C\\cdot\\Sigma^{N}<em>{i=1}\\zeta_i + \\frac{1}{2}||\\pmb{w}||^{2}&#36; subject to &#36;\\zeta_i \\ge 0&#36; and &#36;y</em>{i}(w^{T}x_{i}-b) \\ge 1-\\zeta_i&#36;, where &#36;\\zeta_i = \\Sigma^{N}<em>{i=1}max(0,1-y</em>{i}(\\pmb{w}\\cdot\\pmb{x}_i-b))&#36;</p>\n<ul>\n<li>&#36;y_i&#36; is &#36;-1&#36; or &#36;1&#36; depending on the class of the point &#36;i&#36;</li>\n<li>the class of point &#36;\\pmb{x}&#36; is determined by the SVM using the sign of &#36;(\\pmb{w}\\cdot\\pmb{x}-b)&#36; (ie, on which side of the &#36;(\\pmb{w}\\cdot\\pmb{x}-b)&#36; hyperplane we are).</li>\n</ul>\n<p>Note that you could also use a L1 regularization but it is not implemented in the function we are going to use.</p>\n<p>Indeed if most of the data points are well separated in term of class on each side of the hyperplane then</p>\n<ul>\n<li>most of the time &#36;y_{k}(w^{T}x_{k}-b) \\geq 1&#36; and so &#36;max(0,1-y_{k}(w^{T}x_{k}-b)=0&#36; (that’s good for minimizing our loss function),</li>\n<li>and a few times &#36;y_{k}(w^{T}x_{k}-b) \\leq -1&#36; and so &#36;max(0,1-y_{k}(w^{T}x_{k}-b) \\geq 2&#36; (which is polluting our minimization of the loss function).</li>\n</ul>\n<p>You can see that there is a <a href=\"https://en.wikipedia.org/wiki/Dot_product\">dot product</a> involved : in the case of a linear hyperplane this dot product is just the cartesian dot product that you probably use all the time. It allows you to calculate distances between points in that cartesian space or between points and hyperplanes. But you might be familiar with other scalar product : like for example when you proceed to a Fourier decomposition of a function. This particular scalar product acts on functions and so is not really of interest for us… But others exist.</p>\n<p><strong>So in principle you could use other definitions of distance between points to answer that classification question</strong>. This is what non-linear SVM does and this is why you can choose different so called kernels as hyperparameters as we will see below :</p>\n<p>&#36;\\overrightarrow{x_{i}}.\\overrightarrow{x_{j}}&#36; : cartesian</p>\n<p>&#36;(\\overrightarrow{x_{i}}.\\overrightarrow{x_{j}})^{d}&#36; : polynomial degree d</p>\n<table>\n<tbody>\n<tr>\n<td>&#36;exp(-\\gamma</td>\n<td> </td>\n<td>\\overrightarrow{x_{i}}-\\overrightarrow{x_{j}}</td>\n<td> </td>\n<td>^{2})&#36; : gaussian radial basis</td>\n</tr>\n</tbody>\n</table>\n<p>&#36;tanh(\\kappa\\overrightarrow{x_{i}}.\\overrightarrow{x_{j}}+c)&#36; : hyperbolic tangent</p>\n<p>This is really powerful for classification but going non-linear by using a kernel trick prevents you from interpreting how your features are massaged to create this classifier… So, if you want interpretability and do science rather than engineering : keep it linear.</p>\n<!--<a href=\"image/3d_svm.png\" rel=\"noopener noreferrer\"><img src=\"image/3d_svm.png\"  alt=\"3d_svm. \"   loading=\"lazy\"></a>-->\n<blockquote class=\"comment\" style=\"border: 2px solid #ffecc1; margin: 1em 0.2em\">\n<div class=\"box-title comment-title\" id=\"comment-4\"><i class=\"far fa-comment-dots\" aria-hidden=\"true\" ></i> Comment</div>\n<p>Even though SVM as nothing to do with probablities, we are going to transform the results of our classifier back to probabilities (using logistic regression…) to be able to draw a ROC curve. But again I insist, those are just useful transformations but has actually nothing to do with the technique.</p>\n</blockquote>\n<h3 id=\"toy-example-to-visualize-svmc\">Toy example to visualize SVMC</h3>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-123",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "X2, y2 = make_blobs(n_samples=(250,250), centers=[[-1,-1],[1,1]], random_state=6)\n",
        "plt.scatter(X2[:,0],X2[:,1],c=y2)\n",
        "plt.xlim(min(X2[:,1])-0.5,max(X2[:,1])+0.5)\n",
        "plt.ylim(min(X2[:,1])-0.5,max(X2[:,1])+0.5)\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-124",
      "source": "<!--<a href=\"output_129_0.png\" rel=\"noopener noreferrer\"><img src=\"output_129_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-125",
      "source": [
        "from utils import contour_SVM\n",
        "\n",
        "contour_SVM(X2,y2,c=100,ker='linear')"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-126",
      "source": "<!--<a href=\"output_130_0.png\" rel=\"noopener noreferrer\"><img src=\"output_130_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!--<a href=\"output_130_1.png\" rel=\"noopener noreferrer\"><img src=\"output_130_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!--<a href=\"output_130_2.png\" rel=\"noopener noreferrer\"><img src=\"output_130_2.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-127",
      "source": [
        "contour_SVM(X2,y2,c=0.01,ker='linear')"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-128",
      "source": "<!--<a href=\"output_131_0.png\" rel=\"noopener noreferrer\"><img src=\"output_131_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!--<a href=\"output_131_1.png\" rel=\"noopener noreferrer\"><img src=\"output_131_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!--<a href=\"output_131_2.png\" rel=\"noopener noreferrer\"><img src=\"output_131_2.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-129",
      "source": [
        "contour_SVM(X2,y2,c=1,ker='rbf',gam=10)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-130",
      "source": "<!--<a href=\"output_132_0.png\" rel=\"noopener noreferrer\"><img src=\"output_132_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!--<a href=\"output_132_1.png\" rel=\"noopener noreferrer\"><img src=\"output_132_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!--<a href=\"output_132_2.png\" rel=\"noopener noreferrer\"><img src=\"output_132_2.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-131",
      "source": [
        "contour_SVM(X2,y2,c=1,ker='rbf',gam=1)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-132",
      "source": "<!--<a href=\"output_133_0.png\" rel=\"noopener noreferrer\"><img src=\"output_133_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!--<a href=\"output_133_1.png\" rel=\"noopener noreferrer\"><img src=\"output_133_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!--<a href=\"output_133_2.png\" rel=\"noopener noreferrer\"><img src=\"output_133_2.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-133",
      "source": [
        "contour_SVM(X2,y2,c=1,ker='poly',deg=5)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-134",
      "source": "<!--<a href=\"output_134_0.png\" rel=\"noopener noreferrer\"><img src=\"output_134_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!--<a href=\"output_134_1.png\" rel=\"noopener noreferrer\"><img src=\"output_134_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!--<a href=\"output_134_2.png\" rel=\"noopener noreferrer\"><img src=\"output_134_2.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<h3 id=\"svm-classifier-pipeline\">SVM Classifier pipeline.</h3>\n<p>In sklearn SVM classifier is implemented in a single <code style=\"color: inherit\">sklearn.svm.SVC</code> class,\nbut as we have seen depending on the kernel you have different parameters.</p>\n<p>That means that when you specify the grid of hyper-parameters to explore, you could write something like this:</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-135",
      "source": [
        "grid_values = {\"model__kernel\": ['linear', 'rbf', 'poly'],\n",
        "                 \"model__C\":np.logspace(-2, 2, 10),\n",
        "                 \"model__degree\":[2,3,4,5],\n",
        "                 \"model__gamma\": np.logspace(-2,1,10)}"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-136",
      "source": "<p>That would work, however that means that even though parameter <code style=\"color: inherit\">gamma</code> is useless when the kernel is <code style=\"color: inherit\">'linear'</code>, the GridSearchCV will still test all the different combination of values.\nOn this example, rather than testing :</p>\n<ul>\n<li>10 combinations for linear kernel (C)</li>\n<li>10*4 = 40 combinations for poly kernel (C and degree)</li>\n<li>10*10 = 100 combinations for rbf kernel (C and gamma)</li>\n</ul>\n<p>= 150 combinations to test.</p>\n<p>You would test &#36;3<em>10</em>4*10 = 1200&#36; combinations…</p>\n<p>Let’s see how we can handle this smartly to avoid these useless computations.</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-137",
      "source": [
        "%%time\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "## set up the pipeline as usual\n",
        "pipe = Pipeline([('scalar',StandardScaler()),\n",
        "                 (\"classifier\", SVC())])\n",
        "\n",
        "# the grid of parameter values is not a dictionnary, but now a list\n",
        "#  of dictionnaries : smaller grid to explore independently\n",
        "\n",
        "# for each of these grid, we can re-define locally the classifier\n",
        "grid_param = [  {\"classifier\": [SVC(class_weight='balanced', probability=True, kernel='linear')],\n",
        "                 \"classifier__C\":np.logspace(-2, 2, 10)},\n",
        "                {\"classifier\": [SVC(class_weight='balanced', probability=True, kernel='rbf')],\n",
        "                 \"classifier__C\":np.logspace(-2, 2, 10),\n",
        "                 \"classifier__gamma\": np.logspace(-2,1,10)},\n",
        "                {\"classifier\": [SVC(class_weight='balanced', probability=True, kernel='poly')],\n",
        "                 \"classifier__C\":np.logspace(-2, 2, 10),\n",
        "                 \"classifier__degree\":[2,3,4,5]}]\n",
        "## NB : we use probability = True in order to make ROC auc computation possible later on\n",
        "\n",
        "grid_svm = GridSearchCV(pipe,\n",
        "                        grid_param,\n",
        "                        cv=5,\n",
        "                        verbose=0,\n",
        "                        n_jobs=-1,\n",
        "                        scoring='accuracy')\n",
        "\n",
        "grid_svm.fit(X_train_cancer, y_train_cancer)\n",
        "\n",
        "#get the best cross-validated score\n",
        "print('Grid best score ('+grid_svm.scoring+'): ',\n",
        "      grid_svm.best_score_)\n",
        "# print the best parameters\n",
        "print('Grid best kernel    :' , grid_svm.best_params_[\"classifier\"].kernel )\n",
        "print('Grid best parameter :')\n",
        "for k,v in grid_svm.best_params_.items():\n",
        "    print(' {:>20} : {}'.format(k,v))\n",
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-138",
      "source": "<p>Grid best score (accuracy):  0.9507250341997265\n    Grid best kernel    : rbf\n    Grid best parameter :\n               classifier : SVC(class_weight=’balanced’, probability=True)\n            classifier__C : 35.93813663804626\n        classifier__gamma : 0.1\n    CPU times: user 488 ms, sys: 135 μs, total: 488 ms\n    Wall time: 3.51 s</p>\n<p>Alternatively, the same as above could be done with multiple separate grid searchs. We would <strong>compare them by their cross-validated score</strong> : <code style=\"color: inherit\">grid.best_score_</code>.</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-139",
      "source": [
        "%%time\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "scoring_metric = \"accuracy\"\n",
        "\n",
        "# linear kernel\n",
        "pipe1 = Pipeline([('scalar',StandardScaler()),\n",
        "                 (\"classifier\", SVC(class_weight='balanced', probability=True, kernel='linear'))])\n",
        "grid_param1 = { \"classifier__C\":np.logspace(-2, 2, 10)}\n",
        "\n",
        "grid_svm_linear = GridSearchCV(pipe1, grid_param1,\n",
        "                        cv=5, verbose=0, n_jobs=-1, scoring=scoring_metric)\n",
        "\n",
        "# rbf kernel\n",
        "pipe2 = Pipeline([('scalar',StandardScaler()),\n",
        "                 (\"classifier\", SVC(class_weight='balanced', probability=True, kernel='rbf'))])\n",
        "grid_param2 = { \"classifier__C\":np.logspace(-2, 2, 10) ,\n",
        "               \"classifier__gamma\": np.logspace(-2,1,10)}\n",
        "\n",
        "grid_svm_rbf = GridSearchCV(pipe2, grid_param2,\n",
        "                        cv=5, verbose=0, n_jobs=-1, scoring=scoring_metric)\n",
        "\n",
        "# poly kernel\n",
        "pipe3 = Pipeline([('scalar',StandardScaler()),\n",
        "                 (\"classifier\", SVC(class_weight='balanced', probability=True, kernel='poly'))])\n",
        "grid_param3 = { \"classifier__C\":np.logspace(-2, 2, 10) ,\n",
        "               \"classifier__degree\": [2,3,4,5]}\n",
        "\n",
        "grid_svm_poly = GridSearchCV(pipe3, grid_param3,\n",
        "                        cv=5, verbose=0, n_jobs=-1, scoring=scoring_metric)\n",
        "\n",
        "\n",
        "\n",
        "grid_svm_linear.fit(X_train_cancer, y_train_cancer)\n",
        "grid_svm_rbf.fit(X_train_cancer, y_train_cancer)\n",
        "grid_svm_poly.fit(X_train_cancer, y_train_cancer)\n",
        "\n",
        "\n",
        "print('linear Grid best score ('+grid_svm_linear.scoring+'): ',grid_svm_linear.best_score_)\n",
        "print('   rbf Grid best score ('+grid_svm_rbf.scoring+'): '   ,grid_svm_rbf.best_score_)\n",
        "print('  poly Grid best score ('+grid_svm_poly.scoring+'): '  ,grid_svm_poly.best_score_)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-140",
      "source": "<p>linear Grid best score (accuracy):  0.9366621067031463\n       rbf Grid best score (accuracy):  0.9507250341997265\n      poly Grid best score (accuracy):  0.9201641586867304\n    CPU times: user 544 ms, sys: 20.8 ms, total: 564 ms\n    Wall time: 3.51 s</p>\n<p>In the end we get the same result.</p>\n<blockquote class=\"comment\" style=\"border: 2px solid #ffecc1; margin: 1em 0.2em\">\n<div class=\"box-title comment-title\" id=\"comment-5\"><i class=\"far fa-comment-dots\" aria-hidden=\"true\" ></i> Comment</div>\n<p>This is also the approach we would take to decide between logistic regression, SVM, or other models.</p>\n</blockquote>\n<p>Anyhow, let’s look at the best model performance in more depth:</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-141",
      "source": [
        "y_cancer_test_score=grid_svm.score(X_test_cancer,y_test_cancer)\n",
        "\n",
        "print('Grid best parameter (max.'+grid_svm.scoring+') model on test: ', y_cancer_test_score)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-142",
      "source": "<p>Grid best parameter (max.accuracy) model on test:  0.9090909090909091</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-143",
      "source": [
        "y_cancer_pred_test=grid_svm.predict(X_test_cancer)\n",
        "\n",
        "confusion_m_cancer_SVMC = confusion_matrix(y_test_cancer, y_cancer_pred_test)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(confusion_m_cancer_SVMC, annot=True)\n",
        "\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.title(\"test {} : {:.3f}\".format(grid_svm.scoring , y_cancer_test_score))"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-144",
      "source": "<!--<a href=\"output_141_1.png\" rel=\"noopener noreferrer\"><img src=\"output_141_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-145",
      "source": [
        "\n",
        "y_cancer_score_SVMC = grid_svm.decision_function(X_test_cancer)\n",
        "fpr_SVMC_cancer, tpr_SVMC_cancer, thre_SVMC_cancer = roc_curve(y_test_cancer, y_cancer_score_SVMC)\n",
        "roc_auc_SVMC_cancer = auc(fpr_SVMC_cancer, tpr_SVMC_cancer)\n",
        "\n",
        "proba=expit(thre_SVMC_cancer)\n",
        "for i in range(len(proba)):\n",
        "    if abs(proba[i]-0.5)<0.1:\n",
        "        keep=i\n",
        "        break\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.xlim([-0.01, 1.00])\n",
        "plt.ylim([-0.01, 1.01])\n",
        "plt.plot(fpr_SVMC_cancer, tpr_SVMC_cancer, lw=3, label='SVC ROC curve\\n (area = {:0.2f})'.format(roc_auc_SVMC_cancer))\n",
        "plt.plot(fpr_SVMC_cancer[keep], tpr_SVMC_cancer[keep],'ro',label='threshold=0.5')\n",
        "plt.xlabel('False Positive Rate', fontsize=16)\n",
        "plt.ylabel('True Positive Rate', fontsize=16)\n",
        "plt.title('ROC curve (SVM classifier)', fontsize=16)\n",
        "plt.legend(loc='lower right', fontsize=13)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\n",
        "#plt.axes().set_aspect('equal')\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-146",
      "source": "<!--<a href=\"output_142_0.png\" rel=\"noopener noreferrer\"><img src=\"output_142_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>And here the kernel is RBF, so we have no coefficients to grab from the model for interpretation.</p>\n<p>But, we still have some options.</p>\n<p>For instance, we present here <a href=\"https://scikit-learn.org/stable/modules/permutation_importance.html\">permutation feature importance</a>: it is the <strong>decrease in a model score when a single feature value is randomly shuffled</strong>.</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-147",
      "source": [
        "%%time\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "r = permutation_importance(grid_svm.best_estimator_, X_test_cancer, y_test_cancer,\n",
        "                            n_repeats=1000,\n",
        "                            random_state=132987)\n",
        "\n",
        "for i in r.importances_mean.argsort()[::-1]:\n",
        "    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
        "        print(f\"{breast_cancer_df.columns[i]:<8}\"\n",
        "               f\"{r.importances_mean[i]:.3f}\"\n",
        "               f\" +/- {r.importances_std[i]:.3f}\")\n",
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-148",
      "source": "<p>mean area0.091 +/- 0.022\n    mean concavity0.057 +/- 0.022\n    mean texture0.037 +/- 0.018\n    CPU times: user 7.66 s, sys: 0 ns, total: 7.66 s\n    Wall time: 7.66 s</p>\n<p>Other methods exists to help analyse black-boxxy models, such as <a href=\"https://shap.readthedocs.io/en/latest/example_notebooks/tabular_examples/model_agnostic/Iris%20classification%20with%20scikit-learn.html\">SHAP</a></p>\n<h2 id=\"svm-for-regression\">SVM for Regression</h2>\n<p>We could use the same algorithm for regression, with the only difference that this time instead of finding the hyperplane that is the farthest from the support, we find the hyperplane that is the closest from those support.</p>\n<p>For example, on our diabete data set, just by replacing SVC by SVR.\nWe just use the <code style=\"color: inherit\">'rbf'</code> kernel (the linear and poly have already been tested with our OLS model earlier).</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-149",
      "source": [
        "%%time\n",
        "from sklearn.svm import SVR\n",
        "## SVR for regression\n",
        "\n",
        "pipeline_SVR=Pipeline([('scalar',StandardScaler()),\n",
        "                       ('model',SVR(kernel='rbf'))])\n",
        "\n",
        "grid_values = {\"model__C\":np.logspace(-2, 2, 20),\n",
        "               \"model__gamma\": np.logspace(-2,2,20)}\n",
        "\n",
        "## don't forget to change the metric to one adapted for regression:\n",
        "grid_SVR_diabetes = GridSearchCV(pipeline_SVR,\n",
        "                                 param_grid = grid_values,\n",
        "                                 scoring='r2', n_jobs=-1)\n",
        "\n",
        "grid_SVR_diabetes.fit(X_diabetes_train, y_diabetes_train)\n",
        "\n",
        "print('Grid best score ('+grid_SVR_diabetes.scoring+'): ', grid_SVR_diabetes.best_score_)\n",
        "print('Grid best parameter (max.'+grid_SVR_diabetes.scoring+'): ', grid_SVR_diabetes.best_params_)\n",
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-150",
      "source": "<p>Grid best score (r2):  0.4972454469408552\n    Grid best parameter (max.r2):  {‘model__C’: np.float64(37.92690190732246), ‘model__gamma’: np.float64(0.026366508987303583)}\n    CPU times: user 829 ms, sys: 20.3 ms, total: 849 ms\n    Wall time: 3.44 s</p>\n<p>If you remember, our OLS model was able to get an &#36;R^2&#36; of &#36;~0.52&#36;.</p>\n<p>So we gain a tiny bit of &#36;R^2&#36;, but we loose interpretability … not the best trade here.</p>\n<p>Let’s still have a look at the model predictions :</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-151",
      "source": [
        "y_diabetes_test_score=grid_SVR_diabetes.score(X_diabetes_test,y_diabetes_test)\n",
        "print('Grid best parameter (max.'+grid_SVR_diabetes.scoring+') model on test: ', y_diabetes_test_score)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-152",
      "source": "<p>Grid best parameter (max.r2) model on test:  0.4963096693856498</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-153",
      "source": [
        "## train prediction\n",
        "y_diabetes_train_pred = grid_SVR_diabetes.predict(X_diabetes_train)\n",
        "## test prediction\n",
        "y_diabetes_test_pred  = grid_SVR_diabetes.predict(X_diabetes_test)\n",
        "\n",
        "\n",
        "plt.scatter( y_diabetes_train_pred , y_diabetes_train , c=\"blue\" , label='train set'  )\n",
        "plt.scatter( y_diabetes_test_pred , y_diabetes_test , c=\"red\" , label='test set'  )\n",
        "m,M = min(y_diabetes_train_pred) , max(y_diabetes_train_pred)\n",
        "plt.plot( [m,M] , [m,M] , 'k--' )\n",
        "plt.xlabel( 'predicted values' )\n",
        "plt.ylabel( 'real values' )\n",
        "plt.legend()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-154",
      "source": "<!--<a href=\"output_151_1.png\" rel=\"noopener noreferrer\"><img src=\"output_151_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!-- Exo : try a  linear kernel. Can you say anything about feature importance? How would you compare this new model to the former. %load  solutions/solution_03_mini.py -->\n<h1 id=\"decision-tree-modeling--a-new-loss-function-and-new-ways-to-do-regularization\">Decision tree modeling : a (new?) loss function and new ways to do regularization.</h1>\n<h2 id=\"simple-decision-tree-for-classification\">Simple decision tree for classification.</h2>\n<p>A simple <strong>decision tree</strong> reduces your problem into a <strong>hierarchichal sequence of questions</strong> on your features that can be answered by yes or no and which subdivides the data into 2 subgroups on which a new question is asked, and so on and so on.</p>\n<!--<a href=\"image/tree_ex.png\" rel=\"noopener noreferrer\"><img src=\"image/tree_ex.png\"  alt=\"tree_ex. \"   loading=\"lazy\"></a>-->\n<p>Ok, but a huge number of trees can actually be built just by considering the different orders of questions asked. How does the algorithm deals with this?</p>\n<p>Quite simply actually: it <strong>tests all the features and chooses the most discriminative</strong> (with respect to your target variable) : the feature where a yes or no question divides the data into 2 subsets which minimizes an <strong>impurity measure</strong>.</p>\n<p>Imagine you have a dataset with feature color (red or blue) and feature shape (square or circle), and 2 target classes : 1 and 2.</p>\n<!--<a href=\"image/Tree.png\" rel=\"noopener noreferrer\"><img src=\"image/Tree.png\"  alt=\"tree. \"   loading=\"lazy\"></a>-->\n<p>Asking <code style=\"color: inherit\">\"feature color is red\"</code> gives you the following subgroups:</p>\n<ul>\n<li>10 class 1, and 1 class 2 (<code class=\"language-plaintext highlighter-rouge\">\"feature color is red\" == True</code>)</li>\n<li>2 class 1, and 11 class 2 (<code class=\"language-plaintext highlighter-rouge\">\"feature color is red\" == False</code>)</li>\n</ul>\n<p>Asking <code style=\"color: inherit\">\"feature shape is square\"</code> gives you:</p>\n<ul>\n<li>5 class 1, and 7 class 2 (<code class=\"language-plaintext highlighter-rouge\">True</code>)</li>\n<li>7 class 1 and 5 class 2 (<code class=\"language-plaintext highlighter-rouge\">False</code>)</li>\n</ul>\n<p>So, you will prefer asking <code style=\"color: inherit\">\"feature color is red?\"</code> over <code style=\"color: inherit\">\"feature shape is square?\"</code>: <code style=\"color: inherit\">\"feature color is red?\"</code> is more discriminative.</p>\n<p>For <strong>categorical variables, the questions test for a specific category</strong>.\nFor <strong>numerical variables, the questions use a threshold</strong> to as a yes/no question.</p>\n<p>The <strong>threshold is, again, chosen to minimize impurity</strong>. And in turn the best threshold for a variable is used to estimate the discriminativeness of that variable.</p>\n<p>Of course, you will have to compute this threshold at each step of your tree since at each step you are considering different subdatasets.</p>\n<hr />\n<p>The <strong>impurity is related to how much your feature splitting is still having mixed classes</strong>. So the impurity ends up giving a score: either it is a simple <a href=\"https://en.wikipedia.org/wiki/Entropy_(information_theory)\">Shannon entropy</a> or it is a <a href=\"https://en.wikipedia.org/wiki/Gini_coefficient\">Gini coefficient</a>.</p>\n<h3 id=\"shannon-entropy\">Shannon Entropy</h3>\n\n\\[Entropy = - \\sum\\_{j} p\\_j log\\_2(p\\_j)\\]\n<p>This measure is linked to information theory, where the information of an event occuring is the &#36;log_2&#36; of this event’s probability of occuring.\nFor purity, <strong>0 is the best possible score, and 1 the worst</strong>.</p>\n<h3 id=\"gini-coefficient\">Gini coefficient</h3>\n\n\\[Gini = 1- \\sum\\_{j} p\\_j^2\\]\n<p>The idea is to measure the <strong>probability that a dummy classifier mislabels your data</strong>: <strong>0</strong> is <strong>best, **1</strong> is worst.**</p>\n<p>Before going further, just a little bit of vocabulary:</p>\n<ul>\n<li><strong>Trees</strong> are made of <strong>nodes</strong> (where the question is asked and where the splitting occurs).</li>\n<li>A <strong>branch</strong> is the outcome of a splitting.</li>\n<li>A <strong>leaf</strong> is the last node on a branch (no more splitting).</li>\n</ul>\n<h3 id=\"toy-example-to-visualize-decision-tree\">Toy example to visualize decision tree.</h3>\n<p>Let explore some hyperparameters of this method that, you will see in those examples, act like a regularization:</p>\n<ul>\n<li><strong>Max Tree depth</strong>: the maximum number of consecutive questions to ask</li>\n<li><strong>Min Splitting of nodes</strong>: minimum number of points to consider to make a new rule, outside of the leaves</li>\n<li><strong>Min Splitting of leaves</strong>: minimum number of points to consider to make a new rule, at the leaves</li>\n</ul>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-155",
      "source": [
        "X_3, y_3 = make_blobs(n_samples=120, centers=3,cluster_std=[[1,3],[1,3],[1,3]], random_state=6)\n",
        "plt.scatter(X_3[:,0],X_3[:,1],c=y_3,cmap=plt.cm.coolwarm,edgecolors='k')"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-156",
      "source": "<!--<a href=\"output_157_1.png\" rel=\"noopener noreferrer\"><img src=\"output_157_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-157",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "## creating a decision tree with 1 parameter changed (more on that later)\n",
        "tree = DecisionTreeClassifier(max_depth=3)\n",
        "tree.fit(X_3, y_3)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-158",
      "source": "\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-159",
      "source": [
        "pd.crosstab( tree.predict( X_3 ) , y_3 , rownames=['truth'] , colnames=['prediction'] )"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-160",
      "source": "<div>\n<style scoped=\"\">\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n<thead>\n<tr style=\"text-align: right;\">\n<th>prediction</th>\n<th>0</th>\n<th>1</th>\n<th>2</th>\n</tr>\n<tr>\n<th>truth</th>\n<th></th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<th>0</th>\n<td>35</td>\n<td>2</td>\n<td>0</td>\n</tr>\n<tr>\n<th>1</th>\n<td>5</td>\n<td>38</td>\n<td>0</td>\n</tr>\n<tr>\n<th>2</th>\n<td>0</td>\n<td>0</td>\n<td>40</td>\n</tr>\n</tbody>\n</table>\n</div>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-161",
      "source": [
        "from sklearn.tree import plot_tree\n",
        "fig,ax = plt.subplots(figsize=(14,6))\n",
        "\n",
        "_ = plot_tree( tree , feature_names=['x','y'] ,\n",
        "               fontsize=14 , filled=True , impurity=False , precision=3, ax=ax)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-162",
      "source": "<!--<a href=\"output_160_0.png\" rel=\"noopener noreferrer\"><img src=\"output_160_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-163",
      "source": [
        "from utils import contour_tree\n",
        "contour_tree(X_3, y_3,\n",
        "              crit = 'entropy',\n",
        "              maxd = None,\n",
        "              min_s = 2,\n",
        "              min_l = 1,\n",
        "              max_f = None)\n",
        "#You can see that there are 5 hyperparameters here. Let's see what they do and what they mean.\n",
        "#I bet you can already guess it is going to be related to regularization....\n",
        "# After X,y you have\n",
        "# * crit = 'entropy' which is one way to calculate impurity (you could also put gini here)\n",
        "# * maxd : the max depth of your tree\n",
        "# * min_s : the number of points that should be concerned by the making of a new rule (splitting of the nodes)\n",
        "# * min_l : #of points that should be considered to make a final leaf classification\n",
        "# * max_f maximum number of features to consider for making a new rule..."
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-164",
      "source": "<!--<a href=\"output_161_0.png\" rel=\"noopener noreferrer\"><img src=\"output_161_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!--<a href=\"output_161_1.png\" rel=\"noopener noreferrer\"><img src=\"output_161_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>This is an incredibly complex model.</p>\n<p>Please, note that since every node is a question asked on one particular feature and features are never directly compared, you don’t need scaling! This observation that each question always involves one feature at a time can be also seen in the way the boundaries between classes are made in the graph : there is no diagonal boundaries. You can only see lines parallel to the plot axes.</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-165",
      "source": [
        "#using another impurity measurement\n",
        "contour_tree(X_3, y_3,\n",
        "              crit = 'gini',\n",
        "              maxd = None,\n",
        "              min_s = 2,\n",
        "              min_l = 1,\n",
        "              max_f = None)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-166",
      "source": "<!--<a href=\"output_163_0.png\" rel=\"noopener noreferrer\"><img src=\"output_163_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!--<a href=\"output_163_1.png\" rel=\"noopener noreferrer\"><img src=\"output_163_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>Still some overfitting but it is nice to see that the boundaries are different and that impurity calculations, even if very similar, are making a difference.</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-167",
      "source": [
        "#Imposing a limit for the depth of the tree : how many questions you ask (here set to 4)\n",
        "contour_tree(X_3, y_3,\n",
        "              crit = 'entropy',\n",
        "              maxd = 4,\n",
        "              min_s = 2, min_l = 1, max_f = None)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-168",
      "source": "<!--<a href=\"output_165_0.png\" rel=\"noopener noreferrer\"><img src=\"output_165_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!--<a href=\"output_165_1.png\" rel=\"noopener noreferrer\"><img src=\"output_165_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-169",
      "source": [
        "contour_tree(X_3, y_3,\n",
        "              crit = 'entropy',\n",
        "              maxd = None,\n",
        "              min_s = 2,\n",
        "              min_l = 4,\n",
        "              max_f = None)\n",
        "# min_samples_leaf :\n",
        "#     it sets the minimal number of data points that the chain of rules should concern.\n",
        "\n",
        "# eg. Do you really wish to create a whole new set of rules to explain\n",
        "# only one particular data point?"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-170",
      "source": "<!--<a href=\"output_166_0.png\" rel=\"noopener noreferrer\"><img src=\"output_166_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!--<a href=\"output_166_1.png\" rel=\"noopener noreferrer\"><img src=\"output_166_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-171",
      "source": [
        "contour_tree(X_3, y_3,\n",
        "              crit = 'entropy',\n",
        "              maxd = None,\n",
        "              min_s = 20,\n",
        "              min_l = 1,\n",
        "              max_f = None)\n",
        "# Here it is the same as before but this time it applies to nodes instead of leaves\n",
        "# This parameter is called min_samples_split and is set to 20 here."
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-172",
      "source": "<!--<a href=\"output_167_0.png\" rel=\"noopener noreferrer\"><img src=\"output_167_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!--<a href=\"output_167_1.png\" rel=\"noopener noreferrer\"><img src=\"output_167_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>There are 3 main advantages to this kind of methods:</p>\n<ul>\n<li>it works with all types of feature</li>\n<li>you don’t need to rescale</li>\n<li>it already includes non linear fitting</li>\n</ul>\n<p>Moreover it is ‘easy’ to interpret.</p>\n<p>But….(yes there is a but, there is no free lunch)</p>\n<p>Even with all of those hyperparamaters <strong>they are still not great on new data (inaccuracy…).</strong></p>\n<p>We will see that in the real data example below and we will see more powerful technics based on decision tree that are more costly but generalize better.</p>\n<h3 id=\"single-decision-tree-pipeline\">Single decision tree pipeline.</h3>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-173",
      "source": [
        "## the different hyper parameters on the decision tree are quite related to the dataset size,\n",
        "##  both in number of columns (for max depth)\n",
        "##  and in number of rows (for min sample split and min sample leaf)\n",
        "\n",
        "X_train_cancer.shape"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-174",
      "source": "<p>(426, 10)</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-175",
      "source": [
        "%%time\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "grid_values = {'criterion': ['entropy','gini'],\n",
        "               'max_depth':np.arange(2,X_train_cancer.shape[1]*2),\n",
        "               'min_samples_split':np.arange(2,X_train_cancer.shape[0]//2,20),\n",
        "              'min_samples_leaf':np.arange(1,X_train_cancer.shape[0]//5,10)}\n",
        "\n",
        "grid_tree_cancer = GridSearchCV(DecisionTreeClassifier(class_weight=\"balanced\"),\n",
        "                                param_grid = grid_values,\n",
        "                                scoring='accuracy',\n",
        "                                n_jobs=-1)\n",
        "grid_tree_cancer.fit(X_train_cancer, y_train_cancer)\n",
        "\n",
        "print('Grid best parameter (max. accuracy): ', grid_tree_cancer.best_params_)\n",
        "print('Grid best score (accuracy): ', grid_tree_cancer.best_score_)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-176",
      "source": "<p>Grid best parameter (max. accuracy):  {‘criterion’: ‘entropy’, ‘max_depth’: np.int64(9), ‘min_samples_leaf’: np.int64(11), ‘min_samples_split’: np.int64(2)}\n    Grid best score (accuracy):  0.9412859097127223\n    CPU times: user 3.6 s, sys: 64.5 ms, total: 3.67 s\n    Wall time: 8.84 s</p>\n<div class=\"language-plaintext highlighter-rouge\"><div><pre style=\"color: inherit; background: transparent\"><code style=\"color: inherit\">/home/wandrille/Installed_software/anaconda3/envs/introML2024/lib/python3.11/site-packages/numpy/ma/core.py:2846: RuntimeWarning: invalid value encountered in cast\n  _data = np.array(data, dtype=dtype, copy=copy,\n</code></pre></div></div>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-177",
      "source": [
        "y_cancer_test_score=grid_tree_cancer.score(X_test_cancer,y_test_cancer)\n",
        "\n",
        "print('Grid best parameter (max. accuracy) model on test: ', y_cancer_test_score)\n",
        "\n",
        "y_cancer_pred_test = grid_tree_cancer.predict(X_test_cancer)\n",
        "\n",
        "confusion_m_cancer_tree = confusion_matrix(y_test_cancer, y_cancer_pred_test)\n",
        "plt.figure(figsize=(5.5,4))\n",
        "sns.heatmap(confusion_m_cancer_tree, annot=True)\n",
        "plt.title('test {} : {:.3f}'.format( grid_tree_cancer.scoring , y_cancer_test_score ))\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-178",
      "source": "<!--<a href=\"output_172_2.png\" rel=\"noopener noreferrer\"><img src=\"output_172_2.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>Feature importance can be retrieved from the tree:</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-179",
      "source": [
        "w_tree=grid_tree_cancer.best_estimator_.feature_importances_\n",
        "\n",
        "sorted_features=sorted([[breast_cancer_df.columns[i],abs(w_tree[i])] for i in range(len(w_tree))],\n",
        "                       key=itemgetter(1),reverse=True)\n",
        "\n",
        "print('Features sorted per importance in discriminative process')\n",
        "for f,w in sorted_features:\n",
        "    print('{:>25}\\t{:.3f}'.format(f,w))"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-180",
      "source": "<p>Features sorted per importance in discriminative process\n          mean concave points\t0.741\n                    mean area\t0.093\n               mean perimeter\t0.062\n                 mean texture\t0.050\n               mean concavity\t0.020\n              mean smoothness\t0.018\n       mean fractal dimension\t0.016\n                  mean radius\t0.000\n             mean compactness\t0.000\n                mean symmetry\t0.000</p>\n<p>And we can even plot the model:</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-181",
      "source": [
        "from sklearn.tree import plot_tree\n",
        "fig,ax = plt.subplots(figsize=(25,10))\n",
        "plot_tree( grid_tree_cancer.best_estimator_ ,\n",
        "          feature_names=breast_cancer_df.columns ,\n",
        "          ax=ax , fontsize=10 , filled=True , impurity=False , precision=3)\n",
        "ax.set_title('best single decision tree')"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-182",
      "source": "<!--<a href=\"output_176_1.png\" rel=\"noopener noreferrer\"><img src=\"output_176_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<h2 id=\"random-forest-in-classification\">Random Forest in classification.</h2>\n<p>the Random Forest algorithm relies on two main concepts :</p>\n<ol>\n<li><strong>randomly producing/training many different trees</strong></li>\n<li><strong>agglomerating the predictions</strong> of all these trees (mainly averaging)</li>\n</ol>\n<p>The randomness between trees concerns:</p>\n<ul>\n<li><strong><a href=\"https://en.wikipedia.org/wiki/Bootstrapping_(statistics)\">bootstrapping</a> of the training dataset</strong></li>\n<li>using only a <strong>random subset of features</strong></li>\n</ul>\n<p><strong>Bootstrapping:</strong> sampling methods in which you randomly draw a subsample from your data, <em>with replacement</em>. The created replicate is the same size as the original distribution.</p>\n<p>I am sure you can see intuitively how that is going to help generalization of our model.</p>\n<p>So now on top of all the parameters seen before to create each individual trees of the forest, you also have a parameter controlling the number of trees in your forest.</p>\n<!--<a href=\"image/RF.png\" rel=\"noopener noreferrer\"><img src=\"image/RF.png\"  alt=\"RF. \"   loading=\"lazy\"></a>-->\n<p><strong>In the following plots I am plotting the result for a random forest algorithm and compare it to a single decision tree sharing the same hyperparameters value than the one used in the random forest</strong>.</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-183",
      "source": [
        "from utils import contour_RF\n",
        "\n",
        "contour_RF(X_3,y_3,n_tree = 200,\n",
        "            crit = 'gini', maxd = 4,min_s = 5, min_l = 5, max_f = 'sqrt')\n",
        "#Same as for decision tree except that we have here one more hyperparameter, here\n",
        "# put to 100 and that represents the number of bootstraps\n",
        "# (number of trees trained and then participating to the vote)\n",
        "\n",
        "# also, we restrict the number of variables given to each tree to\n",
        "# the square root of the original number of variables ->  max_f = 'sqrt'"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-184",
      "source": "<!--<a href=\"output_179_0.png\" rel=\"noopener noreferrer\"><img src=\"output_179_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!--<a href=\"output_179_2.png\" rel=\"noopener noreferrer\"><img src=\"output_179_2.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-185",
      "source": [
        "%%time\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "##### Now we use RandomForestClassifier\n",
        "grid_values = {'criterion': ['entropy','gini'],\n",
        "               'n_estimators':[250,500],\n",
        "               'max_depth':np.arange(2,X_train_cancer.shape[1],2),\n",
        "               'min_samples_split':[4,8,16],\n",
        "              'min_samples_leaf':[2,4,8]}\n",
        "\n",
        "grid_RF_cancer = GridSearchCV(RandomForestClassifier(class_weight='balanced'),\n",
        "                              param_grid = grid_values,\n",
        "                              scoring='accuracy',\n",
        "                              cv=5,\n",
        "                              n_jobs=-1)\n",
        "\n",
        "grid_RF_cancer.fit(X_train_cancer, y_train_cancer)\n",
        "\n",
        "print('Grid best score ('+grid_RF_cancer.scoring+'): ', grid_RF_cancer.best_score_)\n",
        "print('Grid best parameter (max. '+grid_RF_cancer.scoring+'): ', grid_RF_cancer.best_params_)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-186",
      "source": "<p>Grid best score (accuracy):  0.9389603283173734\n    Grid best parameter (max. accuracy):  {‘criterion’: ‘entropy’, ‘max_depth’: np.int64(6), ‘min_samples_leaf’: 2, ‘min_samples_split’: 4, ‘n_estimators’: 500}\n    CPU times: user 1.76 s, sys: 98.7 ms, total: 1.86 s\n    Wall time: 1min 34s</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-187",
      "source": [
        "y_test_cancer_score = grid_RF_cancer.score(X_test_cancer,y_test_cancer)\n",
        "\n",
        "print('Grid best parameter (max. '+grid_RF_cancer.scoring+') model on test: ', y_test_cancer_score)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-188",
      "source": "<p>Grid best parameter (max. accuracy) model on test:  0.9370629370629371</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-189",
      "source": [
        "y_pred_test_RF_cancer=grid_RF_cancer.predict(X_test_cancer)\n",
        "\n",
        "confusion_m_RF_cancer = confusion_matrix(y_test_cancer, y_pred_test_RF_cancer)\n",
        "\n",
        "plt.figure(figsize=(5.5,4))\n",
        "sns.heatmap(confusion_m_RF_cancer, annot=True)\n",
        "plt.title('RF - {} : {:.3f}'.format( grid_RF_cancer.scoring ,y_test_cancer_score  ))\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-190",
      "source": "<!--<a href=\"output_182_1.png\" rel=\"noopener noreferrer\"><img src=\"output_182_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-191",
      "source": [
        "feature_importance_RF_cancer = grid_RF_cancer.best_estimator_.feature_importances_\n",
        "\n",
        "## by gathering the importance accross each individual tree, we can access\n",
        "## the standard deviation of this importance\n",
        "std_RF_cancer = np.std([tree.feature_importances_ for tree in grid_RF_cancer.best_estimator_.estimators_],\n",
        "                       axis=0)\n",
        "\n",
        "sorted_idx = np.argsort(feature_importance_RF_cancer)\n",
        "pos = np.arange(sorted_idx.shape[0]) + .5\n",
        "fig = plt.figure(figsize=(12, 12))\n",
        "\n",
        "\n",
        "plt.barh(pos, feature_importance_RF_cancer[sorted_idx],xerr=std_RF_cancer[sorted_idx][::-1], align='center')\n",
        "plt.yticks(pos, np.array(list(breast_cancer_df.columns))[sorted_idx])\n",
        "plt.title('Feature Importance (MDI)',fontsize=10)\n",
        "plt.xlabel(\"Mean decrease in impurity\")\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-192",
      "source": "<!--<a href=\"output_183_0.png\" rel=\"noopener noreferrer\"><img src=\"output_183_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<h2 id=\"random-forest-in-regression\">Random Forest in regression.</h2>\n<p>From the standpoint of tree, the only difference is that now, instead of the entropy or Gini criterion, <strong>the decision which variable to use at any node is made using a regression metric</strong>, such as squared error for example.</p>\n<p>For example, consider this example of <a href=\"https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html\">regression with a single tree</a>, adapted from the sklearn website:</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-193",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "# Create a random dataset\n",
        "rng = np.random.RandomState(1)\n",
        "X = np.sort(5 * rng.rand(80, 1), axis=0)\n",
        "y = np.sin(X).ravel()\n",
        "y[::5] += 3 * (0.5 - rng.rand(16)) # adding additional noise to some of the points\n",
        "\n",
        "# Fit regression model\n",
        "regr_1 = DecisionTreeRegressor(max_depth=2)\n",
        "regr_2 = DecisionTreeRegressor(max_depth=5)\n",
        "regr_1.fit(X, y)\n",
        "regr_2.fit(X, y)\n",
        "\n",
        "# Predict\n",
        "X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]\n",
        "y_1 = regr_1.predict(X_test)\n",
        "y_2 = regr_2.predict(X_test)\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize = (14,6))\n",
        "plt.scatter(X, y, s=20, edgecolor=\"black\", c=\"darkorange\", label=\"data\")\n",
        "plt.plot(X_test, y_1, color=\"cornflowerblue\", label=\"max_depth=2\", linewidth=2)\n",
        "plt.plot(X_test, y_2, color=\"yellowgreen\", label=\"max_depth=5\", linewidth=2)\n",
        "plt.xlabel(\"data\")\n",
        "plt.ylabel(\"target\")\n",
        "plt.title(\"Decision Tree Regression\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-194",
      "source": "<!--<a href=\"output_186_0.png\" rel=\"noopener noreferrer\"><img src=\"output_186_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-195",
      "source": [
        "fig,ax = plt.subplots(figsize=(10,5))\n",
        "plot_tree( regr_1 ,\n",
        "          ax=ax , fontsize=10 , filled=True , impurity=False , precision=3)\n",
        "ax.set_title('best single decision tree')"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-196",
      "source": "<!--<a href=\"output_187_1.png\" rel=\"noopener noreferrer\"><img src=\"output_187_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>Of course with a single tree you do not get very far, unless the tree becomes absolutely huge.</p>\n<p>But with a random forest you can aggregate the estimate from many trees to get somewhere nice.</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-197",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "RFReg = RandomForestRegressor(n_estimators=100 )\n",
        "RFReg.fit(X, y)\n",
        "\n",
        "# Predict\n",
        "X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]\n",
        "y_1 = regr_1.predict(X_test)\n",
        "y_rf = RFReg.predict(X_test)\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize = (14,6))\n",
        "plt.scatter(X, y, s=20, edgecolor=\"black\", c=\"darkorange\", label=\"data\")\n",
        "plt.plot(X_test, y_1, color=\"cornflowerblue\", label=\"max_depth=2\", linewidth=2)\n",
        "plt.plot(X_test, y_rf, color=\"yellowgreen\", label=\"RF\", linewidth=2)\n",
        "plt.xlabel(\"data\")\n",
        "plt.ylabel(\"target\")\n",
        "plt.title(\"Decision Tree Regression\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-198",
      "source": "<!--<a href=\"output_189_0.png\" rel=\"noopener noreferrer\"><img src=\"output_189_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>With a bit of leg-work, we can even grab the inidividual trees predictions to build an interval around the random forest prediction:</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-199",
      "source": [
        "\n",
        "## collecting prediction from all individual trees in a big list\n",
        "y_pred = []\n",
        "x_pred = []\n",
        "for tree in RFReg.estimators_ :\n",
        "    y_pred += list( tree.predict(X_test) )\n",
        "    x_pred += list(X_test[:,0])\n",
        "\n",
        "\n",
        "plt.figure(figsize = (14,6))\n",
        "plt.scatter(X, y, s=20, edgecolor=\"black\", c=\"darkorange\", label=\"data\")\n",
        "plt.plot(X_test, y_1, color=\"cornflowerblue\", label=\"max_depth=2\", linewidth=2)\n",
        "plt.plot(X_test, y_rf, color=\"yellowgreen\", label=\"RF\", linewidth=2)\n",
        "sns.lineplot(x=x_pred , y=y_pred , color=\"yellowgreen\" , errorbar = 'sd')\n",
        "plt.xlabel(\"data\")\n",
        "plt.ylabel(\"target\")\n",
        "plt.title(\"Decision Tree Regression\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-200",
      "source": "<!--<a href=\"output_191_0.png\" rel=\"noopener noreferrer\"><img src=\"output_191_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>Let’s try on the diabetes data:</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-201",
      "source": [
        "X_diabetes_train.shape"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-202",
      "source": "<p>(331, 10)</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-203",
      "source": [
        "%%time\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "## when it comes to criterion, we can now choose:\n",
        "# * “squared_error” (default) for the mean squared error, minimizes the L2 loss\n",
        "#                                           using the mean of each terminal node,\n",
        "# * “friedman_mse”, which uses mean squared error with Friedman’s improvement score for potential splits\n",
        "# * “absolute_error” for the mean absolute error, which minimizes the L1 loss\n",
        "#                                           using the median of each terminal node,\n",
        "# * “poisson” which uses reduction in Poisson deviance to find splits.\n",
        "#\n",
        "# let's try squared error and absolute error\n",
        "\n",
        "grid_values = {'criterion': ['squared_error' , 'absolute_error'],\n",
        "               'n_estimators':[500],\n",
        "               'max_depth':[2,4,8],\n",
        "               'min_samples_split':np.arange(2,len(X_diabetes_train)//5,20),\n",
        "              'min_samples_leaf':np.arange(2,len(X_diabetes_train)//5,20)}\n",
        "\n",
        "grid_RF_diabetes = GridSearchCV(RandomForestRegressor(),\n",
        "                                param_grid = grid_values,\n",
        "                                scoring='r2',n_jobs=-1,cv=3)\n",
        "\n",
        "grid_RF_diabetes.fit(X_diabetes_train, y_diabetes_train)\n",
        "\n",
        "\n",
        "print('Grid best score (r2): ', grid_RF_diabetes.best_score_)\n",
        "print('Grid best parameter (max. r2): ', grid_RF_diabetes.best_params_)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-204",
      "source": "<p>Grid best score (r2):  0.4877900229012484\n    Grid best parameter (max. r2):  {‘criterion’: ‘absolute_error’, ‘max_depth’: 8, ‘min_samples_leaf’: np.int64(2), ‘min_samples_split’: np.int64(22), ‘n_estimators’: 500}\n    CPU times: user 2.77 s, sys: 75.4 ms, total: 2.85 s\n    Wall time: 59.4 s</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-205",
      "source": [
        "y_decision_fn_scores_RF_diabetes=grid_RF_diabetes.score(X_diabetes_test,y_diabetes_test)\n",
        "print('Grid best parameter (max. r2) model on test: ', y_decision_fn_scores_RF_diabetes)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-206",
      "source": "<p>Grid best parameter (max. r2) model on test:  0.4419573864797268</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-207",
      "source": [
        "feature_importance_diabetes=grid_RF_diabetes.best_estimator_.feature_importances_\n",
        "\n",
        "sorted_features=sorted([[df_diabetes.columns[i],abs(feature_importance_diabetes[i])] for i in range(len(feature_importance_diabetes))],key=itemgetter(1),reverse=True)\n",
        "\n",
        "print('Features sorted per importance in discriminative process')\n",
        "for f,w in sorted_features:\n",
        "    print('{:>20}\\t{:.3f}'.format(f,w))"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-208",
      "source": "<p>Features sorted per importance in discriminative process\n                      s5\t0.363\n                     bmi\t0.291\n                      bp\t0.089\n                      s3\t0.057\n                     age\t0.049\n                      s6\t0.044\n                      s2\t0.037\n                      s1\t0.035\n                      s4\t0.030\n                     sex\t0.004</p>\n<p>Tree-based techniques are interesting because:</p>\n<ul>\n<li>they do not necessitate scaling</li>\n<li>they give interpretable models and results</li>\n<li>they model arbitrary non-linear problems</li>\n</ul>\n<p>However as you have seen they tend to take longer to train…</p>\n<h1 id=\"conclusion\">Conclusion</h1>\n<p>During this notebook we have only given a whirlwind tour of what ML is and what is it about.</p>\n<p>We have of course only mentionned a handful of the numerous algorithms that can be used, both for <a href=\"https://scikit-learn.org/stable/supervised_learning.html\">classification and for regression</a> (NB: this link is not an exhaustive list, just what has been implemented in the sklearn library).</p>\n<p>However, more than a collection of algorithm, Machine Learning should also be seen as a set of methods to solve some important statistical problems :</p>\n<ul>\n<li><strong>regularization</strong> parameters (such as l1 or l2 norm, or max depth), to handle <strong>overfitting</strong></li>\n<li><strong>cross-validation</strong> strategies, to detect <strong>overfitting</strong> and handle <strong>model-selection</strong></li>\n<li><strong>adapted metrics</strong> to handle the specific of our goal and our data (handle imbalance for example).\n<ul>\n<li><a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics\">classification metrics</a></li>\n<li><a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics\">regression metrics</a></li>\n</ul>\n</li>\n</ul>\n<h1 id=\"classification-exercise--predicting-heart-disease-on-the-framingham-data-set\">Classification exercise : predicting heart disease on the framingham data-set</h1>\n<p>Use everything you have learned to model and predict the column <code style=\"color: inherit\">'TenYearCHD'</code> (dependent variable : ten year risk of coronary heart disease).</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-209",
      "source": [
        "##separation in X and y\n",
        "X_heart = df_heart.drop( columns = \"TenYearCHD\" )\n",
        "y_heart = df_heart[ \"TenYearCHD\" ]\n",
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-210",
      "source": "\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-211",
      "source": [
        "X_heart.head()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-212",
      "source": "<div>\n<style scoped=\"\">\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n<thead>\n<tr style=\"text-align: right;\">\n<th></th>\n<th>male</th>\n<th>age</th>\n<th>education</th>\n<th>currentSmoker</th>\n<th>cigsPerDay</th>\n<th>BPMeds</th>\n<th>prevalentStroke</th>\n<th>prevalentHyp</th>\n<th>diabetes</th>\n<th>totChol</th>\n<th>sysBP</th>\n<th>diaBP</th>\n<th>BMI</th>\n<th>heartRate</th>\n<th>glucose</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<th>0</th>\n<td>1</td>\n<td>39</td>\n<td>4.0</td>\n<td>0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>195.0</td>\n<td>106.0</td>\n<td>70.0</td>\n<td>26.97</td>\n<td>80.0</td>\n<td>77.0</td>\n</tr>\n<tr>\n<th>1</th>\n<td>0</td>\n<td>46</td>\n<td>2.0</td>\n<td>0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>250.0</td>\n<td>121.0</td>\n<td>81.0</td>\n<td>28.73</td>\n<td>95.0</td>\n<td>76.0</td>\n</tr>\n<tr>\n<th>2</th>\n<td>1</td>\n<td>48</td>\n<td>1.0</td>\n<td>1</td>\n<td>20.0</td>\n<td>0.0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>245.0</td>\n<td>127.5</td>\n<td>80.0</td>\n<td>25.34</td>\n<td>75.0</td>\n<td>70.0</td>\n</tr>\n<tr>\n<th>3</th>\n<td>0</td>\n<td>61</td>\n<td>3.0</td>\n<td>1</td>\n<td>30.0</td>\n<td>0.0</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n<td>225.0</td>\n<td>150.0</td>\n<td>95.0</td>\n<td>28.58</td>\n<td>65.0</td>\n<td>103.0</td>\n</tr>\n<tr>\n<th>4</th>\n<td>0</td>\n<td>46</td>\n<td>3.0</td>\n<td>1</td>\n<td>23.0</td>\n<td>0.0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>285.0</td>\n<td>130.0</td>\n<td>84.0</td>\n<td>23.10</td>\n<td>85.0</td>\n<td>85.0</td>\n</tr>\n</tbody>\n</table>\n</div>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-213",
      "source": [
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-214",
      "source": "<p>Splitting in train/test set</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-215",
      "source": [
        "# %load -r -7 solutions/solution_03_03.py\n",
        "X_train_heart, X_test_heart, y_train_heart, y_test_heart = train_test_split(X_heart,y_heart,\n",
        "                                                   random_state=123456,stratify=y_heart)\n",
        "#stratify is here to make sure that you split keeping the repartition of labels unaffected\n",
        "\n",
        "print(\"fraction of class benign in train\",sum(y_train_heart)/len(y_train_heart))\n",
        "print(\"fraction of class benign in test \",sum(y_test_heart)/len(y_test_heart))\n",
        "print(\"fraction of class benign in full \",sum(y_heart)/len(y_heart))"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-216",
      "source": "<p>fraction of class benign in train 0.15238789646372586\n    fraction of class benign in test  0.15191256830601094\n    fraction of class benign in full  0.15226899945325315</p>\n<p>Logistic regression</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-217",
      "source": [
        "# %load -r 9-33 solutions/solution_03_03.py"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-218",
      "source": "<p>SVM</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-219",
      "source": [
        "# %load -r 34-47 solutions/solution_03_03.py"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-220",
      "source": "<p>random forest</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-221",
      "source": [
        "# %load -r 48-65 solutions/solution_03_03.py"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-222",
      "source": "<p>Evaluation of the best model on the test set</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-223",
      "source": [
        "# %load -r 67-90 solutions/solution_03_03.py"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-224",
      "source": "<p>ROC curve</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-225",
      "source": [
        "# %load -r 93-116 solutions/solution_03_03.py"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-226",
      "source": "<p>getting the most important features</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-227",
      "source": [
        "# %load -r 119-145 solutions/solution_03_03.py"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-228",
      "source": "<p>Additionnal little diagnostic plot</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-229",
      "source": [
        "# %load -r 146- solutions/solution_03_03.py"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-230",
      "source": "<h1 id=\"additionnal-regression-exercise--predicting-daily-maximal-temperature\">Additionnal Regression exercise : predicting daily maximal temperature</h1>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-231",
      "source": [
        "features = pd.read_csv('data/One_hot_temp.csv')\n",
        "features.head(5)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-232",
      "source": "<div>\n<style scoped=\"\">\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n<thead>\n<tr style=\"text-align: right;\">\n<th></th>\n<th>Unnamed: 0</th>\n<th>year</th>\n<th>month</th>\n<th>day</th>\n<th>temp_2</th>\n<th>temp_1</th>\n<th>average</th>\n<th>actual</th>\n<th>forecast_noaa</th>\n<th>forecast_acc</th>\n<th>forecast_under</th>\n<th>friend</th>\n<th>week_Fri</th>\n<th>week_Mon</th>\n<th>week_Sat</th>\n<th>week_Sun</th>\n<th>week_Thurs</th>\n<th>week_Tues</th>\n<th>week_Wed</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<th>0</th>\n<td>0</td>\n<td>2016</td>\n<td>1</td>\n<td>1</td>\n<td>45</td>\n<td>45</td>\n<td>45.6</td>\n<td>45</td>\n<td>43</td>\n<td>50</td>\n<td>44</td>\n<td>29</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n</tr>\n<tr>\n<th>1</th>\n<td>1</td>\n<td>2016</td>\n<td>1</td>\n<td>2</td>\n<td>44</td>\n<td>45</td>\n<td>45.7</td>\n<td>44</td>\n<td>41</td>\n<td>50</td>\n<td>44</td>\n<td>61</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n</tr>\n<tr>\n<th>2</th>\n<td>2</td>\n<td>2016</td>\n<td>1</td>\n<td>3</td>\n<td>45</td>\n<td>44</td>\n<td>45.8</td>\n<td>41</td>\n<td>43</td>\n<td>46</td>\n<td>47</td>\n<td>56</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n</tr>\n<tr>\n<th>3</th>\n<td>3</td>\n<td>2016</td>\n<td>1</td>\n<td>4</td>\n<td>44</td>\n<td>41</td>\n<td>45.9</td>\n<td>40</td>\n<td>44</td>\n<td>48</td>\n<td>46</td>\n<td>53</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n</tr>\n<tr>\n<th>4</th>\n<td>4</td>\n<td>2016</td>\n<td>1</td>\n<td>5</td>\n<td>41</td>\n<td>40</td>\n<td>46.0</td>\n<td>44</td>\n<td>46</td>\n<td>46</td>\n<td>46</td>\n<td>41</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li>year: 2016 for all data points</li>\n<li>month: number for month of the year</li>\n<li>day: number for day of the year</li>\n<li>week: day of the week as a character string</li>\n<li>temp_2: max temperature 2 days prior</li>\n<li>temp_1: max temperature 1 day prior</li>\n<li>average: historical average max temperature</li>\n<li>actual: max temperature measurement</li>\n<li>friend: your friend’s prediction, a random number between 20 below the average and 20 above the average</li>\n</ul>\n<p>Additionally, all the features noted forecast are weather forecast given by some organisation for that day.</p>\n<p>We want to predict <code style=\"color: inherit\">actual</code>, th actual max temperature of a day.</p>\n<p>Use a random forest to do so. You can inspire yourself from the examples of code above.</p>\n<p>Here are a couple of plots to get you started with the data exploration:</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-233",
      "source": [
        "import datetime\n",
        "feature_list=list(features.columns)\n",
        "labels=features[\"actual\"]\n",
        "# Dates of training values\n",
        "months = np.array(features)[:, feature_list.index('month')]\n",
        "days = np.array(features)[:, feature_list.index('day')]\n",
        "years = np.array(features)[:, feature_list.index('year')]\n",
        "\n",
        "# List and then convert to datetime object\n",
        "dates = [str(int(year)) + '-' + str(int(month)) + '-' + str(int(day)) for year, month, day in zip(years, months, days)]\n",
        "dates = [datetime.datetime.strptime(date, '%Y-%m-%d') for date in dates]\n",
        "\n",
        "# Dataframe with true values and dates\n",
        "true_data = pd.DataFrame(data = {'date': dates, 'actual': labels})\n",
        "\n",
        "\n",
        "plt.xlabel('Date');\n",
        "plt.ylabel('Maximum Temperature (F)')\n",
        "\n",
        "# Plot the actual values\n",
        "plt.plot(true_data['date'], true_data['actual'], 'b-', label = 'actual')\n",
        "plt.xticks(rotation = '60');\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-234",
      "source": "<!--<a href=\"output_223_0.png\" rel=\"noopener noreferrer\"><img src=\"output_223_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-235",
      "source": [
        "import datetime\n",
        "feature_list=list(features.columns)\n",
        "labels=features[\"average\"]\n",
        "# Dates of training values\n",
        "months = np.array(features)[:, feature_list.index('month')]\n",
        "days = np.array(features)[:, feature_list.index('day')]\n",
        "years = np.array(features)[:, feature_list.index('year')]\n",
        "\n",
        "# List and then convert to datetime object\n",
        "dates = [str(int(year)) + '-' + str(int(month)) + '-' + str(int(day)) for year, month, day in zip(years, months, days)]\n",
        "dates = [datetime.datetime.strptime(date, '%Y-%m-%d') for date in dates]\n",
        "\n",
        "# Dataframe with true values and dates\n",
        "true_data = pd.DataFrame(data = {'date': dates, 'average': labels})\n",
        "\n",
        "\n",
        "plt.xlabel('Date');\n",
        "plt.ylabel('Maximum Temperature (F)')\n",
        "\n",
        "# Plot the average values\n",
        "plt.plot(true_data['date'], true_data['average'], 'b-', label = 'average')\n",
        "plt.xticks(rotation = '60');\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-236",
      "source": "<!--<a href=\"output_224_0.png\" rel=\"noopener noreferrer\"><img src=\"output_224_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>Solution - Read in data</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-237",
      "source": [
        "# %load -r 1-5 solutions/solution_03_02.py"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-238",
      "source": "<p>Solution - train/test split</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-239",
      "source": [
        "# %load -r 8-17 solutions/solution_03_02.py"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-240",
      "source": "<p>Solution - setup and fit pipeline</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-241",
      "source": [
        "# %load -r 19-34 solutions/solution_03_02.py"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-242",
      "source": "<p>Solution - evaluate the model on the test set</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-243",
      "source": [
        "# %load -r 36-40 solutions/solution_03_02.py"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-244",
      "source": "<p>Solution - get the feature importances</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-245",
      "source": [
        "# %load -r 41-49 solutions/solution_03_02.py"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-246",
      "source": "<p>Solution - using permutation to get the importances</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-247",
      "source": [
        "# %load -r 50-73 solutions/solution_03_02.py"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-248",
      "source": "<p>Solution - BONUS - re-thinking the splitting strategy</p>\n<!--<a href=\"image/TimeSeriesSplit.png\" rel=\"noopener noreferrer\"><img src=\"image/TimeSeriesSplit.png\"  alt=\"RF. \"   loading=\"lazy\"></a>-->\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-249",
      "source": [
        "# %load solutions/solution_03_02ter.py"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-250",
      "source": "<p>Solution - BONUS - an even better splitting strategy</p>\n<!--<a href=\"image/BlockedTimeSeriesSplit.png\" rel=\"noopener noreferrer\"><img src=\"image/BlockedTimeSeriesSplit.png\"  alt=\"RF. \"   loading=\"lazy\"></a>-->\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-251",
      "source": [
        "# %load solutions/solution_03_02quat.py"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-252",
      "source": "<h1 id=\"annexes\">Annexes</h1>\n<h2 id=\"features-selection\">Features selection</h2>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-253",
      "source": [
        "df=sns.load_dataset(\"iris\")\n",
        "# Here we use the data loader from seaborn but such data loaders also exist with scikit-learn and are more generally delt\n",
        "#with the dataframe handler pandas\n",
        "df.head()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-254",
      "source": "<div>\n<style scoped=\"\">\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n<thead>\n<tr style=\"text-align: right;\">\n<th></th>\n<th>sepal_length</th>\n<th>sepal_width</th>\n<th>petal_length</th>\n<th>petal_width</th>\n<th>species</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<th>0</th>\n<td>5.1</td>\n<td>3.5</td>\n<td>1.4</td>\n<td>0.2</td>\n<td>setosa</td>\n</tr>\n<tr>\n<th>1</th>\n<td>4.9</td>\n<td>3.0</td>\n<td>1.4</td>\n<td>0.2</td>\n<td>setosa</td>\n</tr>\n<tr>\n<th>2</th>\n<td>4.7</td>\n<td>3.2</td>\n<td>1.3</td>\n<td>0.2</td>\n<td>setosa</td>\n</tr>\n<tr>\n<th>3</th>\n<td>4.6</td>\n<td>3.1</td>\n<td>1.5</td>\n<td>0.2</td>\n<td>setosa</td>\n</tr>\n<tr>\n<th>4</th>\n<td>5.0</td>\n<td>3.6</td>\n<td>1.4</td>\n<td>0.2</td>\n<td>setosa</td>\n</tr>\n</tbody>\n</table>\n</div>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-255",
      "source": [
        "sns.pairplot(df,hue=\"species\")\n",
        "# Seaborn allows you to 'split' your data according to a chosen parameter hue. Here I chose to color split the data according\n",
        "#to the target\n",
        "#description diagonal"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-256",
      "source": "<!--<a href=\"output_247_1.png\" rel=\"noopener noreferrer\"><img src=\"output_247_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<p>What do you get from the plots above?</p>\n<p>Looking at the diagonal of these plots : petal features separate the species more efficiently than sepal features.</p>\n<p>There is a very strong correlation between <code style=\"color: inherit\">petal_length</code> and <code style=\"color: inherit\">petal_width</code> : those two features are probably so similar that keeping them both could be redundant.</p>\n<p>The least correlation visible seems to be between <code style=\"color: inherit\">sepal_width</code> and all the others.</p>\n<p>By itself <code style=\"color: inherit\">sepal_width</code> is not good at differentiating species but associated with other features we can already see groups forming by species. And since they are very much non-colinear I would say that, in dimension two, <code style=\"color: inherit\">petal_length</code> and <code style=\"color: inherit\">sepal_width</code> are already a good pick for low dimensions models.</p>\n<p>You can actually quantify the correlation between features by calling the <code style=\"color: inherit\">corr()</code> function in pandas. You would prefer (and sometime is requiered) having a subset of features that are not correlated to each others.</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-257",
      "source": [
        "df_corr = df.corr()\n",
        "\n",
        "sns.clustermap(df_corr,\n",
        "               figsize=(8,8),\n",
        "               z_score=None,\n",
        "               row_cluster=True,\n",
        "               col_cluster=True,\n",
        "               method='ward',\n",
        "               cmap='coolwarm',vmax=1,vmin=-1,\n",
        "               annot=True, annot_kws={\"size\": 13},cbar_kws={\"label\": 'Pearson\\ncorrelation'})\n",
        "## sns allows you to do a hierarchical clustering that simply\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-258",
      "source": "<!--<a href=\"output_249_0.png\" rel=\"noopener noreferrer\"><img src=\"output_249_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<h3 id=\"classification\">Classification</h3>\n<p>One thing (among others) that you can do is to look for a <strong>subset of features that seems to be important to describe the target class</strong>. It’s like the pairplots above but instead of just looking at it you choose the features you want to keep.</p>\n<p>You can choose different metrics for ‘how important to describe the class’ a feature is.\nMany of those metrics utilize concepts that we haven’t introduced yet, in contexts that we haven’t seen yet, so I will introduce two metrics for classification that don’t need too much of <em>a priori</em> knowledge.</p>\n<p><code style=\"color: inherit\">Scikit-learn</code> lets you specify a threshold on the features are kept, either as:</p>\n<ul>\n<li>a direct number: <code style=\"color: inherit\">SelectKBest</code>.</li>\n<li>important features from a percentile of your top importance score: <code style=\"color: inherit\">SelectPercentile</code>.</li>\n<li>an error type: <code style=\"color: inherit\">SelectFpr</code> or <code style=\"color: inherit\">SelectFdr</code> (see course 2 logistic regression part).</li>\n</ul>\n<p><code style=\"color: inherit\">Scikit-learn</code> offers you different scores to calculate the importance of your features.</p>\n<ul>\n<li><strong>ANOVA-F</strong> : F=&#36;\\frac{Var_{feature_i}(Between_class)}{Var_{feature_i}(Within_class)}&#36;.</li>\n</ul>\n<p>          \n<strong>F</strong> itself gives you how much a feature &#36;i&#36; variance is different between classes, normalized by the intrinsic variance of that feature per class.</p>\n<p>          \nSo if <strong>F</strong> is big it means that the variation that you observe between classes is big compared to the variance of this feature :</p>\n<p>          \nit behaves differently for different classes so it it is a good feature to keep for the classification.</p>\n<p>          \nTo this <strong>F</strong> is associated a <strong>p-value</strong> that you would use for scoring.</p>\n<ul>\n<li><strong>Chi2</strong> (&#36;\\chi^{2}&#36;) test.</li>\n</ul>\n<p>          \nYou suppose the null hypothesis that this feature &#36;i&#36; is homogenously distributed among classes</p>\n<p>          \nand so you are expecting that its representation in different classes should be very similar to what you can calculate for the bulk data</p>\n<p>          \n i.e. &#36;\\frac{\\Sigma^{n_points} feature_{i}}{n_points}&#36;.</p>\n<p>          \nYou then compare the actual distribution of this feature in different classes to your null model predictions. If this <strong>sum of square differences</strong>:</p>\n<p>          \n&#36;\\Sigma^{n_class}<em>{k}\\frac{(expected_form_null_hypothesis</em>{k}-observed_{k})^{2}}{observed}&#36;</p>\n<p>          \nis big then the null hypothesis has to be rejected and this feature is significant for classifying.</p>\n<p>          \nThe sum of these square quantities over the different classes asymptotically follows a &#36;\\chi^{2}&#36;</p>\n<p>          \ndistribution and thus you have access to a <strong>p-value for scoring</strong>.</p>\n<p>Another score would be to use the amount of <a href=\"https://en.wikipedia.org/wiki/Mutual_information\">Mutual Information</a> shared between a feature and our target.</p>\n<p>The way this mutual information is caclulated is out of the scope of this class as it is a bit technical.</p>\n<p>For regression just use correlation or Mutual Information</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-259",
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "skb = SelectKBest(chi2, k=2)#creating the object SelectKBest and settling for 2 best features (k=2) in term of chi2 score\n",
        "skb.fit(df[list(df.columns)[:-1]], df[list(df.columns)[-1]])#calculating the chi2 for each features\n",
        "\n",
        "dico_pval={df.columns[i]:v for i,v in enumerate(skb.pvalues_)}\n",
        "print(\"features Chi2 scores (p-values):\")#all the features and the chi2 pvalues associated. use .pvalues_\n",
        "for feature,pval in dico_pval.items() :\n",
        "    print('\\t',feature , ':' , pval )\n",
        "\n",
        "X_new=skb.transform(df[list(df.columns)[:-1]])# keep only the k=2 best features according to the score\n",
        "\n",
        "print(\"New data with only the k=2 best features kept :\")\n",
        "print(X_new[:5,]) #printing only the 5 first entries\n",
        "print('...')"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-260",
      "source": "<p>features Chi2 scores (p-values):\n         sepal_length : 0.004476514990225755\n         sepal_width : 0.15639598043162506\n         petal_length : 5.533972277193705e-26\n         petal_width : 2.7582496530033412e-15\n    New data with only the k=2 best features kept :\n    [[1.4 0.2]\n     [1.4 0.2]\n     [1.3 0.2]\n     [1.5 0.2]\n     [1.4 0.2]]\n    …</p>\n<h3 id=\"multi-classes\">Multi classes</h3>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-261",
      "source": [
        "X3, y3 = make_blobs(n_samples=120, centers=3,cluster_std=3, random_state=6)# 120 points, 3 blobs/clusters with some spread=3\n",
        "#Random_state is here just to be sure that every time you will get the same blobs. If you change the random_state or do not\n",
        "#specify it then you will get a new plot every time you call the function (random seed)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-262",
      "source": "<p>Of course all of that can be applied to a multi-classes classification. How is it tipically done?</p>\n<p>There are many different ways of tackling the problem, that end up being a combination of these 4 elements :</p>\n<ul>\n<li>\n<p><strong>Either you treat the problem as one class vs one class</strong>.</p>\n</li>\n<li><strong>Or you treat the problem as a one class vs the rest : you subdivide the problem into three different problems either your are class 1 and you consider the other classes as being one big class “non 1”, and you do the same for the other class</strong>.</li>\n<li><strong>You change your loss function to a multinomial one : softmax intead of a sigmoid.</strong></li>\n</ul>\n<p>In any case you need to decide <strong>how you are going to agglomerate those different statistics (different ROC curves for example)</strong>:</p>\n<ul>\n<li><strong>micro average</strong> : pull all raw numbers together (eg. number of FP, TP), group them and then calculate your overall statistic (eg. TPR)</li>\n<li><strong>macro average</strong> : calculate each statistics separately and then do the average.</li>\n</ul>\n<p>Think about the differences induced by those metrics. Why should you use one more than the other? Or maybe you should always use all of them?</p>\n<p>Spoiler it has to do with overall separability and balance between the different class.</p>\n<p>What strategy your logistic regression uses so you can plot the right curves, is a tricky question. For a first pass on your data always set the multiclasses method to be ovr (one vs rest) : understanding the hyperplanes relation to decision probability and the ROC curve is more intuitive that way, and I believe less sensitive to imbalance dataset.</p>\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-263",
      "source": [
        "from utils import contour_lr_more\n",
        "#one vs rest implementation\n",
        "contour_lr_more('l2',X3,y3,10,'ovr')\n",
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-264",
      "source": "<!--<a href=\"output_255_0.png\" rel=\"noopener noreferrer\"><img src=\"output_255_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!--<a href=\"output_255_1.png\" rel=\"noopener noreferrer\"><img src=\"output_255_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!--<a href=\"output_255_2.png\" rel=\"noopener noreferrer\"><img src=\"output_255_2.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "id": "cell-265",
      "source": [
        "from utils import contour_lr_more\n",
        "#softmax implementation (something only available with logistic regression), and again different from one vs one\n",
        "#and one vs rest\n",
        "contour_lr_more('l2',X3,y3,10,'multinomial')\n",
        ""
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "attributes": {
          "classes": [
            "%autoreload 2"
          ],
          "id": ""
        }
      }
    },
    {
      "id": "cell-266",
      "source": "<!--<a href=\"output_256_0.png\" rel=\"noopener noreferrer\"><img src=\"output_256_0.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!--<a href=\"output_256_1.png\" rel=\"noopener noreferrer\"><img src=\"output_256_1.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n<!--<a href=\"output_256_2.png\" rel=\"noopener noreferrer\"><img src=\"output_256_2.png\"  alt=\"png. \"   loading=\"lazy\"></a>-->\n",
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "id": "final-ending-cell",
      "metadata": {
        "editable": false,
        "collapsed": false
      },
      "source": [
        "# Key Points\n\n",
        "- To be added\n",
        "\n# Congratulations on successfully completing this tutorial!\n\n",
        "Please [fill out the feedback on the GTN website](https://training.galaxyproject.org/training-material/topics/statistics/tutorials/intro-to-ml-with-python/tutorial.html#feedback) and check there for further resources!\n"
      ]
    }
  ]
}